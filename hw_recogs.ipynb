{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9804d50-4eb0-4f1d-a20d-d6c3dbb0fd65",
      "metadata": {
        "id": "e9804d50-4eb0-4f1d-a20d-d6c3dbb0fd65"
      },
      "source": [
        "# Homework and bakeoff: Compositional generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c401fbca-fc3d-4e35-bb84-15b1ce9b974f",
      "metadata": {
        "id": "c401fbca-fc3d-4e35-bb84-15b1ce9b974f"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Christopher Potts and Zhengxuan Wu\"\n",
        "__version__ = \"CS224u, Stanford, Spring 2023\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117fc266-35fd-4321-beb2-8805073ebcdf",
      "metadata": {
        "id": "117fc266-35fd-4321-beb2-8805073ebcdf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_recogs.ipynb)\n",
        "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/cgpotts/cs224u/blob/master/hw_recogs.ipynb)\n",
        "\n",
        "If Colab is opened with this badge, please save a copy to drive (from the File menu) before running the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2111f33-11d7-455d-a1cb-5f0c828559dd",
      "metadata": {
        "id": "e2111f33-11d7-455d-a1cb-5f0c828559dd"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c392958-5e6c-4a57-88b6-dc2880928692",
      "metadata": {
        "id": "2c392958-5e6c-4a57-88b6-dc2880928692"
      },
      "source": [
        "This assignment is about _compositional generalization_. We are going to assess the degree to which our apparently very good models have learned to process and interpret language _systematically_. To do this, we are going to ask them to interpret novel combinations of familiar words and phrases. For humans, these tasks are very easy. For our models, the situation seems to be quite different.\n",
        "\n",
        "The basis for the assignment is the ReCOGS dataset of [Wu, Manning, and Potts 2023](https://arxiv.org/abs/2303.13716). ReCOGS modifies the COGS dataset of [Kim and Linzen 2020](https://aclanthology.org/2020.emnlp-main.731) in a number of ways, with the goal of more directly assessing the interpretive abilities of models.\n",
        "\n",
        "The assignment questions are fairly diverse. Question 1 asks you to conduct a specific analysis of the ReCOGS dataset, and Question 2 follows this up with a corresponding analysis of the errors made by a top-performing ReCOGS model. For Question 3, you try some in-context learning with DSP. And then we open things up as usual: you can do anything you want for your original system, and you enter that system's predictions into a bakeoff.\n",
        "\n",
        "There is only one rule that we need to enforce throughout this work:\n",
        "\n",
        "__You cannot train your system on any examples from `dataset[\"gen\"]`, nor can the output representations from those examples be included in any prompts used for in-context learning.__\n",
        "\n",
        "The nature of your original system is otherwise unconstrained."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62709719-bfb2-45fe-908f-8ea72caf2470",
      "metadata": {
        "id": "62709719-bfb2-45fe-908f-8ea72caf2470"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "07497e3f-50cc-4224-b04b-23b7ed5577c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07497e3f-50cc-4224-b04b-23b7ed5577c9",
        "outputId": "d75dbecc-8969-409a-dc88-c5f7f68fc229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cs224u'...\n",
            "remote: Enumerating objects: 2272, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 2272 (delta 85), reused 128 (delta 67), pack-reused 2092\u001b[K\n",
            "Receiving objects: 100% (2272/2272), 41.87 MiB | 9.68 MiB/s, done.\n",
            "Resolving deltas: 100% (1384/1384), done.\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 2)) (1.11.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: nltk>=3.7 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 5)) (3.8.1)\n",
            "Requirement already satisfied: pytest>=7.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 6)) (7.4.1)\n",
            "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 8)) (1.5.3)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 10)) (0.14.1)\n",
            "Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 11)) (4.26.1)\n",
            "Requirement already satisfied: datasets==2.10.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 12)) (2.10.1)\n",
            "Requirement already satisfied: spacy==3.5.1 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 13)) (3.5.1)\n",
            "Requirement already satisfied: dsp-ml<0.2 in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 14)) (0.1.8)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 15)) (0.28.0)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (from -r cs224u/requirements.txt (line 16)) (4.27)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r cs224u/requirements.txt (line 9)) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r cs224u/requirements.txt (line 9)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r cs224u/requirements.txt (line 9)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r cs224u/requirements.txt (line 9)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r cs224u/requirements.txt (line 9)) (11.7.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1->-r cs224u/requirements.txt (line 10)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1->-r cs224u/requirements.txt (line 10)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (0.17.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r cs224u/requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (3.8.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (0.18.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (2.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (3.3.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r cs224u/requirements.txt (line 9)) (0.41.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->-r cs224u/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->-r cs224u/requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.7->-r cs224u/requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (2.0.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.4.4)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->-r cs224u/requirements.txt (line 8)) (2023.3.post1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from dsp-ml<0.2->-r cs224u/requirements.txt (line 14)) (2.2.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from dsp-ml<0.2->-r cs224u/requirements.txt (line 14)) (5.8.0)\n",
            "Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.10/dist-packages (from cohere->-r cs224u/requirements.txt (line 16)) (1.8.2)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere->-r cs224u/requirements.txt (line 16)) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere->-r cs224u/requirements.txt (line 16)) (2.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r cs224u/requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere->-r cs224u/requirements.txt (line 16)) (3.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->-r cs224u/requirements.txt (line 10)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1->-r cs224u/requirements.txt (line 10)) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (0.1.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.6.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.1->-r cs224u/requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.5.7)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.19.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf cs224u/\n",
        "!git clone https://github.com/pcadmanbosse/cs224u\n",
        "!pip install -r cs224u/requirements.txt\n",
        "import sys\n",
        "sys.path.append(\"cs224u\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b7d665d-000e-4bae-83a8-1f7c78879df5",
      "metadata": {
        "id": "0b7d665d-000e-4bae-83a8-1f7c78879df5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from compgen import recogs_exact_match"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da265b5-a622-4f75-b0df-60cc53f7273e",
      "metadata": {
        "id": "5da265b5-a622-4f75-b0df-60cc53f7273e"
      },
      "source": [
        "The default location of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "23eaea62-edd6-4f41-add5-353b186782ba",
      "metadata": {
        "id": "23eaea62-edd6-4f41-add5-353b186782ba"
      },
      "outputs": [],
      "source": [
        "SRC_DIRNAME = os.path.join(\"data\", \"recogs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b11f934-f2c3-4bc3-8c5f-d3dbbd450eb1",
      "metadata": {
        "id": "7b11f934-f2c3-4bc3-8c5f-d3dbbd450eb1"
      },
      "source": [
        "The following code should grab the dataset for you; if it fails for any reason, you can manually download it from [this link](https://web.stanford.edu/class/cs224u/data/recogs.tgz) and then put it in `SRC_DIRNAME`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b902be49-6380-46ae-a353-a634b1cab256",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b902be49-6380-46ae-a353-a634b1cab256",
        "outputId": "477ac974-7fd4-44e0-9c0f-2c1b889f770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-22 15:41:55--  https://web.stanford.edu/class/cs224u/data/recogs.tgz\n",
            "Resolving web.stanford.edu (web.stanford.edu)... 171.67.215.200, 2607:f6d0:0:925a::ab43:d7c8\n",
            "Connecting to web.stanford.edu (web.stanford.edu)|171.67.215.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7075025 (6.7M) [application/x-gzip]\n",
            "Saving to: ‘data/recogs.tgz’\n",
            "\n",
            "recogs.tgz          100%[===================>]   6.75M  5.43MB/s    in 1.2s    \n",
            "\n",
            "2023-09-22 15:41:56 (5.43 MB/s) - ‘data/recogs.tgz’ saved [7075025/7075025]\n",
            "\n",
            "recogs/\n",
            "recogs/._train.tsv\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "recogs/train.tsv\n",
            "recogs/._tgt_vocab.txt\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "recogs/tgt_vocab.txt\n",
            "recogs/._decoder_config.json\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "recogs/decoder_config.json\n",
            "recogs/._dev.tsv\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "recogs/dev.tsv\n",
            "recogs/._encoder_config.json\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "recogs/encoder_config.json\n",
            "recogs/._src_vocab.txt\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "recogs/src_vocab.txt\n",
            "recogs/._test.tsv\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "recogs/test.tsv\n",
            "recogs/._cs224u-recogs-test-unlabeled.tsv\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.macromates.visibleIndex'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.macromates.selectionRange'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "recogs/cs224u-recogs-test-unlabeled.tsv\n",
            "recogs/._gen.tsv\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "recogs/gen.tsv\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(SRC_DIRNAME):\n",
        "    !mkdir -p data\n",
        "    !wget https://web.stanford.edu/class/cs224u/data/recogs.tgz -P data\n",
        "    !tar xvf data/recogs.tgz -C data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da14956-1813-4372-b747-d7a2dbd10bc1",
      "metadata": {
        "id": "5da14956-1813-4372-b747-d7a2dbd10bc1"
      },
      "source": [
        "## Load the COGS and ReCOGS datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "49118e3a-a4fc-4a6a-9d88-c0f8371a390c",
      "metadata": {
        "id": "49118e3a-a4fc-4a6a-9d88-c0f8371a390c"
      },
      "outputs": [],
      "source": [
        "def load_split(filename):\n",
        "    return pd.read_csv(\n",
        "        filename,\n",
        "        delimiter=\"\\t\",\n",
        "        names=['input', 'output', 'category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5fda2c30-a788-4a62-806c-f7318797474d",
      "metadata": {
        "id": "5fda2c30-a788-4a62-806c-f7318797474d"
      },
      "outputs": [],
      "source": [
        "dataset = {}\n",
        "\n",
        "for splitname in (\"train\", \"dev\", \"gen\"):\n",
        "    dataset[splitname] = load_split(f\"{SRC_DIRNAME}/{splitname}.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e5a50d3-6f83-4c66-bea5-548ccf25ba7a",
      "metadata": {
        "id": "5e5a50d3-6f83-4c66-bea5-548ccf25ba7a"
      },
      "source": [
        "Here's a look at the dataset. Fundamentally, the task is to map simple English sentences to logical forms. For ReCOGS, you need only predict these forms up to semantic equivalence, which means that we abstract away from the order of the conjuncts and the names of specific variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f6900c28-1949-419b-a8e4-9d534f973dae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6900c28-1949-419b-a8e4-9d534f973dae",
        "outputId": "3366854d-99c8-4319-8af2-34b1d9af8a34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "135546"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8265b340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "8265b340",
        "outputId": "719decac-ab78-4d05-faff-ec54091b762b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f141fb7a-cc63-4b03-8798-48bc681eedf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A rose was helped by a dog .</td>\n",
              "      <td>rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND them...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sailor dusted a boy .</td>\n",
              "      <td>* sailor ( 48 ) ; boy ( 53 ) ; dust ( 10 ) AND...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emma rolled a teacher .</td>\n",
              "      <td>Emma ( 17 ) ; teacher ( 50 ) ; roll ( 39 ) AND...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Evelyn rolled the girl .</td>\n",
              "      <td>Evelyn ( 46 ) ; * girl ( 16 ) ; roll ( 21 ) AN...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cake was forwarded to Levi by Charlotte .</td>\n",
              "      <td>cake ( 5 ) ; Levi ( 34 ) ; Charlotte ( 33 ) ; ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The captain ate .</td>\n",
              "      <td>* captain ( 56 ) ; eat ( 46 ) AND agent ( 46 ,...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The girl needed to cook .</td>\n",
              "      <td>* girl ( 51 ) ; need ( 14 ) AND agent ( 14 , 5...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A cake rolled .</td>\n",
              "      <td>cake ( 33 ) ; roll ( 39 ) AND theme ( 39 , 33 )</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The cookie was passed to Emma .</td>\n",
              "      <td>* cookie ( 20 ) ; Emma ( 16 ) ; pass ( 28 ) AN...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Emma ate the ring beside a bed .</td>\n",
              "      <td>Emma ( 10 ) ; * ring ( 24 ) ; bed ( 0 ) ; nmod...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A horse gave the cake beside a table to the mo...</td>\n",
              "      <td>horse ( 59 ) ; * cake ( 15 ) ; table ( 24 ) ; ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Amelia gave Emma a strawberry .</td>\n",
              "      <td>Amelia ( 5 ) ; Emma ( 47 ) ; strawberry ( 18 )...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A cat disintegrated a girl .</td>\n",
              "      <td>cat ( 30 ) ; girl ( 26 ) ; disintegrate ( 59 )...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Eleanor sold Evelyn the cake .</td>\n",
              "      <td>Eleanor ( 36 ) ; Evelyn ( 12 ) ; * cake ( 38 )...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The book was lended to Benjamin by a cat .</td>\n",
              "      <td>* book ( 16 ) ; Benjamin ( 31 ) ; cat ( 45 ) ;...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The cake was frozen by the giraffe .</td>\n",
              "      <td>* cake ( 12 ) ; * giraffe ( 8 ) ; freeze ( 13 ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The donut was studied .</td>\n",
              "      <td>* donut ( 36 ) ; study ( 8 ) AND theme ( 8 , 36 )</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Isabella forwarded a box on a tree to Emma .</td>\n",
              "      <td>Isabella ( 30 ) ; box ( 11 ) ; tree ( 22 ) ; E...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A cake was stabbed by Scarlett .</td>\n",
              "      <td>cake ( 35 ) ; Scarlett ( 1 ) ; stab ( 14 ) AND...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>A pencil was fed to Liam by the deer .</td>\n",
              "      <td>pencil ( 47 ) ; Liam ( 40 ) ; * deer ( 5 ) ; f...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f141fb7a-cc63-4b03-8798-48bc681eedf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f141fb7a-cc63-4b03-8798-48bc681eedf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f141fb7a-cc63-4b03-8798-48bc681eedf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c966b7e5-0ac6-4e9e-816b-68c8ada05437\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c966b7e5-0ac6-4e9e-816b-68c8ada05437')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c966b7e5-0ac6-4e9e-816b-68c8ada05437 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                input  \\\n",
              "0                        A rose was helped by a dog .   \n",
              "1                           The sailor dusted a boy .   \n",
              "2                             Emma rolled a teacher .   \n",
              "3                            Evelyn rolled the girl .   \n",
              "4         A cake was forwarded to Levi by Charlotte .   \n",
              "5                                   The captain ate .   \n",
              "6                           The girl needed to cook .   \n",
              "7                                     A cake rolled .   \n",
              "8                     The cookie was passed to Emma .   \n",
              "9                    Emma ate the ring beside a bed .   \n",
              "10  A horse gave the cake beside a table to the mo...   \n",
              "11                    Amelia gave Emma a strawberry .   \n",
              "12                       A cat disintegrated a girl .   \n",
              "13                     Eleanor sold Evelyn the cake .   \n",
              "14         The book was lended to Benjamin by a cat .   \n",
              "15               The cake was frozen by the giraffe .   \n",
              "16                            The donut was studied .   \n",
              "17       Isabella forwarded a box on a tree to Emma .   \n",
              "18                   A cake was stabbed by Scarlett .   \n",
              "19             A pencil was fed to Liam by the deer .   \n",
              "\n",
              "                                               output         category  \n",
              "0   rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND them...  in_distribution  \n",
              "1   * sailor ( 48 ) ; boy ( 53 ) ; dust ( 10 ) AND...  in_distribution  \n",
              "2   Emma ( 17 ) ; teacher ( 50 ) ; roll ( 39 ) AND...  in_distribution  \n",
              "3   Evelyn ( 46 ) ; * girl ( 16 ) ; roll ( 21 ) AN...  in_distribution  \n",
              "4   cake ( 5 ) ; Levi ( 34 ) ; Charlotte ( 33 ) ; ...  in_distribution  \n",
              "5   * captain ( 56 ) ; eat ( 46 ) AND agent ( 46 ,...  in_distribution  \n",
              "6   * girl ( 51 ) ; need ( 14 ) AND agent ( 14 , 5...  in_distribution  \n",
              "7     cake ( 33 ) ; roll ( 39 ) AND theme ( 39 , 33 )  in_distribution  \n",
              "8   * cookie ( 20 ) ; Emma ( 16 ) ; pass ( 28 ) AN...  in_distribution  \n",
              "9   Emma ( 10 ) ; * ring ( 24 ) ; bed ( 0 ) ; nmod...  in_distribution  \n",
              "10  horse ( 59 ) ; * cake ( 15 ) ; table ( 24 ) ; ...  in_distribution  \n",
              "11  Amelia ( 5 ) ; Emma ( 47 ) ; strawberry ( 18 )...  in_distribution  \n",
              "12  cat ( 30 ) ; girl ( 26 ) ; disintegrate ( 59 )...  in_distribution  \n",
              "13  Eleanor ( 36 ) ; Evelyn ( 12 ) ; * cake ( 38 )...  in_distribution  \n",
              "14  * book ( 16 ) ; Benjamin ( 31 ) ; cat ( 45 ) ;...  in_distribution  \n",
              "15  * cake ( 12 ) ; * giraffe ( 8 ) ; freeze ( 13 ...  in_distribution  \n",
              "16  * donut ( 36 ) ; study ( 8 ) AND theme ( 8 , 36 )  in_distribution  \n",
              "17  Isabella ( 30 ) ; box ( 11 ) ; tree ( 22 ) ; E...  in_distribution  \n",
              "18  cake ( 35 ) ; Scarlett ( 1 ) ; stab ( 14 ) AND...  in_distribution  \n",
              "19  pencil ( 47 ) ; Liam ( 40 ) ; * deer ( 5 ) ; f...  in_distribution  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# in_distribution                            119984\n",
        "# length_ood                                  15360\n",
        "# primitive                                     143\n",
        "# exposure_example_unacc_subj                     5\n",
        "# exposure_example_unacc                          5\n",
        "# exposure_example_subj_common                    5\n",
        "# exposure_example_obj_proper                     5\n",
        "# exposure_example_pp_dative                      5\n",
        "# exposure_example_subj_proper                    5\n",
        "# exposure_example_obj_common                     5\n",
        "# exposure_example_transitive_subj                5\n",
        "# exposure_example_obj_omitted_transitive         5\n",
        "# exposure_example_active                         5\n",
        "# exposure_example_do_dative                      5\n",
        "# exposure_example_passive                        4\n",
        "\n",
        "\n",
        "dataset['train'][dataset['train']['category'] == 'in_distribution'].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03961b86-b824-4c5f-8e54-8258b71a6466",
      "metadata": {
        "id": "03961b86-b824-4c5f-8e54-8258b71a6466"
      },
      "source": [
        "The `dataset['gen']` section is divided up into different 21 categories. A category name `X_to_Y` or `only_seen_as_X_as_Y`  means that specific phrases were seen only as `X` in training and will encounter those phrases as `Y` at test time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9eb7e84b-5304-4d4c-a0a5-919ff79a7730",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eb7e84b-5304-4d4c-a0a5-919ff79a7730",
        "outputId": "bdcbf107-64a4-4bbb-990a-bcf38a9695b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['active_to_passive',\n",
              " 'cp_recursion',\n",
              " 'do_dative_to_pp_dative',\n",
              " 'obj_omitted_transitive_to_transitive',\n",
              " 'obj_pp_to_subj_pp',\n",
              " 'obj_to_subj_common',\n",
              " 'obj_to_subj_proper',\n",
              " 'only_seen_as_transitive_subj_as_unacc_subj',\n",
              " 'only_seen_as_unacc_subj_as_obj_omitted_transitive_subj',\n",
              " 'only_seen_as_unacc_subj_as_unerg_subj',\n",
              " 'passive_to_active',\n",
              " 'pp_dative_to_do_dative',\n",
              " 'pp_recursion',\n",
              " 'prim_to_inf_arg',\n",
              " 'prim_to_obj_common',\n",
              " 'prim_to_obj_proper',\n",
              " 'prim_to_subj_common',\n",
              " 'prim_to_subj_proper',\n",
              " 'subj_to_obj_common',\n",
              " 'subj_to_obj_proper',\n",
              " 'unacc_to_transitive']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(dataset['gen'].category.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5264a754-0903-40bf-8012-9abd9d7a41dc",
      "metadata": {
        "id": "5264a754-0903-40bf-8012-9abd9d7a41dc"
      },
      "source": [
        "## Question 1: Proper names and their semantic roles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989aaeec-4de8-4d7f-a90f-334117b4ea04",
      "metadata": {
        "id": "989aaeec-4de8-4d7f-a90f-334117b4ea04"
      },
      "source": [
        "A number of the COGS/ReCOGS generalization categories assess models on their ability to handle proper names appearing in novel positions at test time. For example, in the `obj_to_subj_proper` category, models encounter proper names that appeared in the train set only in grammatical object position (e.g., _see Sandy_), and then they are asked to make predictions about cases where those names are grammatical subjects (_Sandy left_). These changes have systematic effects on the grammatical roles that the meanings of these names play semantically. In particular, subjects are likely to play `agent` roles and objects are likely to play `theme` roles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4acb7cb6-5e43-4697-89eb-c16c592209b1",
      "metadata": {
        "id": "4acb7cb6-5e43-4697-89eb-c16c592209b1"
      },
      "source": [
        "### Task 1: Pattern-based analysis function [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "552d0f81-cd75-4895-9414-1ada5c9c9f28",
      "metadata": {
        "id": "552d0f81-cd75-4895-9414-1ada5c9c9f28"
      },
      "source": [
        "Write a function that scans ReCOGS logical forms to determine what role proper names play. The following are the core steps:\n",
        "\n",
        "1. Identify proper names. All and only proper names begin with capital letters in these LFs, and proper names consist only of ascii letters. The format is, informally, `Name ( d+ )`, as in `Sandy ( 47 )`.\n",
        "\n",
        "2. Identify role expressions. The pattern is always `role ( d+ , d+ )`, as in `agent ( 1 , 47 )`. Here, the first variable is for the associated event, and the second is the role argument. The possible roles are `agent`, `theme`, and `recipient`. (The dataset includes other roles, but these involve events, not people.)\n",
        "\n",
        "3. Determine which of the above are linked in the sense that the variable names are the same. A given name can link to multiple role expressions (or none at all), and LFs can contain multiple names and multiple role expressions.\n",
        "\n",
        "To do the above, you just need to complete the function `get_propername_role`. The test should clear up any ambiguity and help you iterate to a solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "f3a19570-3a3c-4843-a9de-f48f2b746dfe",
      "metadata": {
        "id": "f3a19570-3a3c-4843-a9de-f48f2b746dfe"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_propername_role(s):\n",
        "    \"\"\"Extract from `s` all the pairs `(name, role)` determined by\n",
        "    binding relationships. There can be multiple tokens of the same\n",
        "    name with different variables, as in \"Kim ( 1 )\" and \"Kim ( 47 )\",\n",
        "    and there can be instances in which a single name with variable\n",
        "    like \"Kim ( 1 )\" binds into multiple role expressions like\n",
        "    \"agent ( 4 , 1 )\" and \"theme ( 6 , 1 )\". Your function should\n",
        "    cover all these cases.\n",
        "\n",
        "    We've suggested a particular program design to get you started,\n",
        "    but you are free to do something different and perhaps cleverer\n",
        "    if you wish!\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s: str\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    set of tuples `(name, role)` where `name` and `role` are str\n",
        "    \"\"\"\n",
        "    # Step 1: Define a regex for \"name ( var )\" expressions:\n",
        "    ##### YOUR CODE HERE\n",
        "    name_pattern = r\"([A-Z][a-z]+) \\(\\s*(\\d+)\\s*\\)\"\n",
        "\n",
        "\n",
        "    # Step 2: Define a regex for \"role ( var , var )\" expressions:\n",
        "    ##### YOUR CODE HERE\n",
        "    role_pattern = r\"([a-z]+) (\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\))\"\n",
        "\n",
        "\n",
        "    # Step 3: Use `findall` with both of your regexs:\n",
        "    ##### YOUR CODE HERE\n",
        "    names = re.findall(name_pattern, s)\n",
        "    roles = re.findall(role_pattern, s)\n",
        "\n",
        "    nameMap = {\n",
        "\n",
        "    }\n",
        "    roleMap = {\n",
        "\n",
        "    }\n",
        "\n",
        "    for nameres in names:\n",
        "        nameMap[nameres[1]] = nameres[0]\n",
        "    for roleres in roles:\n",
        "        if roleres[3] in roleMap:\n",
        "            roleMap[roleres[3]].append(roleres[0])\n",
        "        else:\n",
        "            roleMap[roleres[3]] = [roleres[0]]\n",
        "\n",
        "    # Step 4: Loop overall combinations of matches from your regexs\n",
        "    # to build `data` as a set of pairs `(name, role)`:\n",
        "    data = set()\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "    for id, name in nameMap.items():\n",
        "        if id in roleMap:\n",
        "            for role in roleMap[id]:\n",
        "                data.add((name, role))\n",
        "\n",
        "\n",
        "    # Step 5: Return `data`:\n",
        "    ##### YOUR CODE HERE\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "60f3e98e-78f2-4096-b5df-db38700997dc",
      "metadata": {
        "id": "60f3e98e-78f2-4096-b5df-db38700997dc"
      },
      "outputs": [],
      "source": [
        "def test_get_propername_role(func):\n",
        "    examples = [\n",
        "        # Standard case:\n",
        "        (\n",
        "            \"Bella ( 7 ) ; smile ( 4 ) AND agent ( 4 , 7 )\",\n",
        "            {(\"Bella\", \"agent\")}\n",
        "        ),\n",
        "        # No binding:\n",
        "        (\n",
        "            \"Riley ( 37 ) ; theme ( 4 , 7 )\",\n",
        "            set()\n",
        "        ),\n",
        "        # Two tokens of the same name referring to different entities:\n",
        "        (\n",
        "            \"Riley ( 37 ) ; Riley ( 4 ) ; theme ( 1 , 37 ) AND agent ( 1 , 4 )\",\n",
        "            {(\"Riley\", \"theme\"), (\"Riley\", \"agent\")},\n",
        "        ),\n",
        "        # Two names:\n",
        "        (\n",
        "            \"Riley ( 4 ) ; Emma ( 243 ) ; recipient ( 6 , 4 ) AND agent ( 6 , 243 )\",\n",
        "            {(\"Riley\", \"recipient\"), (\"Emma\", \"agent\")},\n",
        "        ),\n",
        "        # One name binding into multiple role expressions:\n",
        "        (\n",
        "            \"Riley ( 4 ) ; agent ( 6 , 4 ) AND theme ( 6 , 4 )\",\n",
        "            {(\"Riley\", \"theme\"), (\"Riley\", \"agent\")},\n",
        "        ),\n",
        "        # Nothing to match:\n",
        "        (\n",
        "            \"no proper names\",\n",
        "            set()\n",
        "        )\n",
        "    ]\n",
        "    errcount = 0\n",
        "    for ex, expected in examples:\n",
        "        result = func(ex)\n",
        "        if expected != result:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{func.__name__}`:\"\n",
        "                  f\"\\n\\tInput: {ex}\"\n",
        "                  f\"\\n\\tExpected: {expected}\"\n",
        "                  f\"\\n\\tGot: {result}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors detected for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "01c1d893-6e10-4913-8852-b0df7da1eb67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01c1d893-6e10-4913-8852-b0df7da1eb67",
        "outputId": "64436ec2-fa37-4dfd-ebdd-e5a6aecd4a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors detected for `get_propername_role`\n"
          ]
        }
      ],
      "source": [
        "test_get_propername_role(get_propername_role)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7908627-e0ac-4f97-bfd9-55a83ba70d3a",
      "metadata": {
        "id": "d7908627-e0ac-4f97-bfd9-55a83ba70d3a"
      },
      "source": [
        "### Task 2: Finding challenging names [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab578426-4f74-4e93-879c-e40d8ab92fc7",
      "metadata": {
        "id": "ab578426-4f74-4e93-879c-e40d8ab92fc7"
      },
      "source": [
        "You can now use your code to find the names that will be the most challenging because their train/gen roles are disjoint. To do this, you just need to complete the function `find_name_roles`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "728fe9a2-35a7-47d3-98b9-56a13362f5c0",
      "metadata": {
        "id": "728fe9a2-35a7-47d3-98b9-56a13362f5c0"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def find_name_roles(split_df, colname=\"output\"):\n",
        "    \"\"\"Create a map from names to dicts mapping roles to counts: the\n",
        "    number of time the name appears with role in `split_df`:\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    split_df : pd.DataFrame\n",
        "        Needs to have a column called `colname`.\n",
        "    colname: str\n",
        "        Column to target with `get_propername_role`. Default: \"output\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    `defaultdict` mapping names to roles to counts\n",
        "    \"\"\"\n",
        "    # This is a convenient way to create a multidimensional count dict:\n",
        "    # You can access it out of the box as `all_roles[key1][key2] += 1`.\n",
        "    all_roles = defaultdict(lambda : defaultdict(int))\n",
        "\n",
        "    # Apply `get_propername_role` to every value in the target column\n",
        "    # and aggregate the results into `all_roles`:\n",
        "    ##### YOUR CODE HERE\n",
        "    for index, row in split_df.iterrows():\n",
        "        data = get_propername_role(row[colname])\n",
        "        for name, role in data:\n",
        "            all_roles[name][role] += 1\n",
        "\n",
        "\n",
        "    # Return `all_roles`:\n",
        "    return all_roles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57613848-3acd-4114-b5f0-49374d7e4c5b",
      "metadata": {
        "id": "57613848-3acd-4114-b5f0-49374d7e4c5b"
      },
      "source": [
        "A quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "72997def-1245-4c25-98f6-c7a601e35593",
      "metadata": {
        "id": "72997def-1245-4c25-98f6-c7a601e35593"
      },
      "outputs": [],
      "source": [
        "def test_find_name_roles(func):\n",
        "    df = pd.DataFrame({\n",
        "        \"tester\": [\n",
        "            \"Bella ( 7 ) ; agent ( 4 , 7 )\",\n",
        "            \"Bella ( 7 ) ; agent ( 4 , 7 )\",\n",
        "            \"Riley ( 37 ) ; agent ( 4 , 37 )\",\n",
        "            \"Riley ( 3 ) ; theme ( 4 , 3 )\",\n",
        "            \"Emma ( 37 ) ; theme ( 4 , 7 )\"\n",
        "        ]})\n",
        "    expected = {\n",
        "        \"Bella\": {\"agent\": 2},\n",
        "        \"Riley\": {\"agent\": 1, \"theme\": 1}\n",
        "    }\n",
        "    result = func(df, colname=\"tester\")\n",
        "    if result != expected:\n",
        "        print(f\"Error for `{func.__name__}`:\"\n",
        "              f\"\\n\\tExpected:{expected}\"\n",
        "              f\"\\n\\tGot: {result}\")\n",
        "    else:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eb1e75e4-d5f0-4181-85d9-73b9d8b1db8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1e75e4-d5f0-4181-85d9-73b9d8b1db8d",
        "outputId": "bc491acf-50f4-4581-eb1b-486a82fe6ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors found for `find_name_roles`\n"
          ]
        }
      ],
      "source": [
        "test_find_name_roles(find_name_roles)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6532c822-d02f-4930-b119-d167ee797384",
      "metadata": {
        "id": "6532c822-d02f-4930-b119-d167ee797384"
      },
      "source": [
        "Once the test passes, this analysis should be informative:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bb0c22b2-845e-41b8-a958-e5cd9628bf7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb0c22b2-845e-41b8-a958-e5cd9628bf7c",
        "outputId": "9e8043a3-5bbd-47d5-c688-08ae7b740a30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Charlie', defaultdict(int, {'theme': 10})),\n",
              " ('Lina', defaultdict(int, {'agent': 5})),\n",
              " ('Jayden', defaultdict(int, {'agent': 165, 'recipient': 60}))]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_roles = find_name_roles(dataset['train'])\n",
        "\n",
        "sorted(train_roles.items(), key=lambda x: len(x[1]))[: 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3dc45e2a-78ef-46fd-8119-e054c58b148a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dc45e2a-78ef-46fd-8119-e054c58b148a",
        "outputId": "eced7ec1-c40f-49d2-9511-e0e3fbd8bff4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Charlie', defaultdict(int, {'agent': 1000})),\n",
              " ('Lina', defaultdict(int, {'theme': 1000})),\n",
              " ('Paula', defaultdict(int, {'agent': 1000, 'theme': 1000}))]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen_roles = find_name_roles(dataset[\"gen\"])\n",
        "\n",
        "sorted(gen_roles.items(), key=lambda x: len(x[1]))[: 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9338e56-1171-48f0-ab8a-0c556d2dfdbf",
      "metadata": {
        "id": "d9338e56-1171-48f0-ab8a-0c556d2dfdbf"
      },
      "source": [
        "We will return to these troublemakers in a bit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6517a076-72b5-4837-8898-fef1f8339657",
      "metadata": {
        "id": "6517a076-72b5-4837-8898-fef1f8339657"
      },
      "source": [
        "## Pretrained ReCOGS models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0076aa3-9eea-475d-aea4-b7653a865120",
      "metadata": {
        "id": "f0076aa3-9eea-475d-aea4-b7653a865120"
      },
      "source": [
        "We launch now into an extended interlude before Question 2. For Question 2, you will work with a ReCOGS model that we trained for you. This interlude presents the code needed to work with this model. We are exposing these details to you in case you want to use this code to train or fine-tune your own models for your original system."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c3e96e-dfc8-4e75-9b24-51e7f33a781e",
      "metadata": {
        "id": "80c3e96e-dfc8-4e75-9b24-51e7f33a781e"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43392af3-cc12-449e-9301-983a3d554737",
      "metadata": {
        "id": "43392af3-cc12-449e-9301-983a3d554737"
      },
      "source": [
        "Here is a function for creating Hugging Face `PreTrainedTokenizerFast` tokenizers based on a provided vocab file. It pretty much just splits on whitespace and adds special tokens. Chris originally planned to have writing this be a homework question, but it turned out to be very difficult and confusing for him to write, so he decided to just present it to you in the hope that it helps you with similar tasks in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "de55c95c-ef3d-453f-9336-97e9e93e31c2",
      "metadata": {
        "id": "de55c95c-ef3d-453f-9336-97e9e93e31c2"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "\n",
        "def get_tokenizer(vocab_filename):\n",
        "    with open(vocab_filename) as f:\n",
        "        vocab = f.read().splitlines()\n",
        "    vocab_size = len(vocab)\n",
        "    vocab = dict(zip(vocab, list(range(vocab_size))))\n",
        "    tok = Tokenizer(WordLevel(vocab, unk_token='[UNK]'))\n",
        "    # This definitely needs to be done here and in the construction of\n",
        "    # `PreTrainedTokenizerFast`. Don't be tempted to \"clean this up\"!\n",
        "    tok.add_special_tokens([\"[BOS]\", \"[UNK]\", \"[PAD]\", \"[EOS]\"])\n",
        "    tok.pre_tokenizer = WhitespaceSplit()\n",
        "    tok.post_processor = TemplateProcessing(\n",
        "        single=f\"[BOS]:0 $A:0 [EOS]:0\",\n",
        "        special_tokens=[\n",
        "            (\"[BOS]\", tok.token_to_id(\"[BOS]\")),\n",
        "            (\"[EOS]\", tok.token_to_id(\"[EOS]\"))])\n",
        "    return PreTrainedTokenizerFast(\n",
        "        tokenizer_object=tok,\n",
        "        bos_token=\"[BOS]\",\n",
        "        unk_token=\"[UNK]\",\n",
        "        pad_token=\"[PAD]\",\n",
        "        eos_token=\"[EOS]\",\n",
        "        # This vital; otherwise any periods will have their leading\n",
        "        # spaces removed, which is wrong for COGS/ReCOGS.\n",
        "        clean_up_tokenization_spaces=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a541a47b-a3ed-421c-bb9e-59f3b5f7f2af",
      "metadata": {
        "id": "a541a47b-a3ed-421c-bb9e-59f3b5f7f2af"
      },
      "source": [
        "We will have separate tokens for the encoder and the decoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "aa80d0a2-4599-4212-9bdb-a6d06263a0b8",
      "metadata": {
        "id": "aa80d0a2-4599-4212-9bdb-a6d06263a0b8"
      },
      "outputs": [],
      "source": [
        "enc_tokenizer = get_tokenizer(os.path.join(SRC_DIRNAME, \"src_vocab.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1fa0fc58-7b49-4e19-98c9-369eb4b3ce64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fa0fc58-7b49-4e19-98c9-369eb4b3ce64",
        "outputId": "d2e89d67-8da2-4a4c-c851-bb2154822103"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[BOS]', 'A', 'sailor', 'was', 'helped', '[EOS]']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_tokenizer.tokenize(\n",
        "    \"A sailor was helped\",\n",
        "    add_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fb21e534-1d80-4642-983b-96fa415fdaba",
      "metadata": {
        "id": "fb21e534-1d80-4642-983b-96fa415fdaba"
      },
      "outputs": [],
      "source": [
        "dec_tokenizer = get_tokenizer(os.path.join(SRC_DIRNAME, \"tgt_vocab.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "474ceec8-6378-45e3-ac52-659d442f259d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "474ceec8-6378-45e3-ac52-659d442f259d",
        "outputId": "d3f2cab5-4a74-4441-e201-8fa01a142893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[BOS]',\n",
              " 'sailor',\n",
              " '(',\n",
              " '53',\n",
              " ')',\n",
              " ';',\n",
              " 'help',\n",
              " '(',\n",
              " '7',\n",
              " ')',\n",
              " 'AND',\n",
              " 'theme',\n",
              " '(',\n",
              " '7',\n",
              " ',',\n",
              " '53',\n",
              " ')',\n",
              " '[EOS]']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_tokenizer.tokenize(\n",
        "    \"sailor ( 53 ) ; help ( 7 ) AND theme ( 7 , 53 )\",\n",
        "    add_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25600c63-2c1f-47e7-82ed-a9f5eacb73b7",
      "metadata": {
        "id": "25600c63-2c1f-47e7-82ed-a9f5eacb73b7"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1ede76-83b6-4573-8067-f50dfc97e5dd",
      "metadata": {
        "id": "4c1ede76-83b6-4573-8067-f50dfc97e5dd"
      },
      "source": [
        "Next is a dataset utility. Chris was originally going to have you write this yourselves, since it is useful to know how to write these utilities, and the task is really just to use our tokenizers appropriately. However, since `collate_fn` has to be a static method with fixed arguments, we can't easily pass in these tokenizers to it! As a result, we have to do all the tokenization at once ahead of time and then redo all the masking work for each batch. So Chris did this for you in the hope that this will be useful to you in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2857b954-c426-4f47-a9c3-10761203883d",
      "metadata": {
        "id": "2857b954-c426-4f47-a9c3-10761203883d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class RecogsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, enc_tokenizer, dec_tokenizer, X, y=None):\n",
        "        self.X = [enc_tokenizer.encode(s) for s in X]\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = [dec_tokenizer.encode(s) for s in y]\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"Unfortunately, we can't pass the tokenizer in as an argument\n",
        "        to this method, since it is a static method, so we need to do\n",
        "        the work of creating the necessary attention masks.\"\"\"\n",
        "        def get_pad_and_mask(vals):\n",
        "            lens = [len(i) for i in vals]\n",
        "            maxlen = max(lens)\n",
        "            pad = []\n",
        "            mask = []\n",
        "            for ex, length in zip(vals, lens):\n",
        "                diff = maxlen - length\n",
        "                pad.append(ex + ([0] * diff))\n",
        "                mask.append(([1] * length) + ([0] * diff))\n",
        "            return torch.tensor(pad), torch.tensor(mask)\n",
        "        batch_elements = list(zip(*batch))\n",
        "        X = batch_elements[0]\n",
        "        X_pad, X_mask = get_pad_and_mask(X)\n",
        "        if len(batch_elements) == 1:\n",
        "            return X_pad, X_mask\n",
        "        else:\n",
        "            y = batch_elements[1]\n",
        "            y_pad, y_mask = get_pad_and_mask(y)\n",
        "            # Repeat `y_pad` because our optimizer expects to find\n",
        "            # labels in final position. These will not be used because\n",
        "            # Hugging Face will calculate the loss for us.\n",
        "            return X_pad, X_mask, y_pad, y_mask, y_pad\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return (self.X[idx],)\n",
        "        else:\n",
        "            return (self.X[idx], self.y[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3021faf-dfa6-4d89-9a39-5b4546ac2008",
      "metadata": {
        "id": "c3021faf-dfa6-4d89-9a39-5b4546ac2008"
      },
      "source": [
        "The following just illustrate how to work with the above utility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3586efad-f12d-4811-8345-e7b18fc46ae9",
      "metadata": {
        "id": "3586efad-f12d-4811-8345-e7b18fc46ae9"
      },
      "outputs": [],
      "source": [
        "ex_dataset = RecogsDataset(\n",
        "    enc_tokenizer,\n",
        "    dec_tokenizer,\n",
        "    dataset['train'].input.head(20),\n",
        "    y=dataset['train'].output.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b80b9ddc-cc02-4b0c-863d-8453fc5bf450",
      "metadata": {
        "id": "b80b9ddc-cc02-4b0c-863d-8453fc5bf450"
      },
      "outputs": [],
      "source": [
        "ex_dataloader = torch.utils.data.DataLoader(\n",
        "    ex_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    collate_fn=ex_dataset.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a08b88f4-abc9-4921-8bf6-78c9c4157198",
      "metadata": {
        "id": "a08b88f4-abc9-4921-8bf6-78c9c4157198"
      },
      "outputs": [],
      "source": [
        "ex_batch = iter(ex_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ef750fa-794c-4fe0-a27f-330377521db3",
      "metadata": {
        "id": "5ef750fa-794c-4fe0-a27f-330377521db3"
      },
      "source": [
        "This will show you batches. Since `batch_size=2` for `dataloader`, this will be a tuple where each element has two lists. The structure is determined by `collate_fn` in `RecogsDataset`:\n",
        "\n",
        "`X_pad, X_mask, y_pad, y_mask, y_pad`\n",
        "\n",
        "where `y_pad` is repeated in the final position to meet the interface specifications of `torch_base_model.py`, in case you decide to train models yourself. (See details below; Hugging Face calculates the loss itself, which is ultimately nice but a bit non-standard.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "016cb2a5-869a-4860-af8a-c94e7586128e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "016cb2a5-869a-4860-af8a-c94e7586128e",
        "outputId": "ccf9eb56-596c-46e5-97c0-ee05339762b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[  1, 115, 297, 744, 669,  17,   2,   0,   0],\n",
              "         [  1,  18, 203, 744, 659, 199, 108,  17,   2]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              " tensor([[  1,   7, 331,   5,  40,   6,  67, 647,   5,  65,   6,  68, 664,   5,\n",
              "           65,   8,  40,   6,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0],\n",
              "         [  1, 247,   5,  39,   6,  67, 159,   5,  11,   6,  67, 637,   5,  16,\n",
              "            6,  68, 664,   5,  16,   8,  39,   6,  68, 177,   5,  16,   8,  11,\n",
              "            6,   2]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1]]),\n",
              " tensor([[  1,   7, 331,   5,  40,   6,  67, 647,   5,  65,   6,  68, 664,   5,\n",
              "           65,   8,  40,   6,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0],\n",
              "         [  1, 247,   5,  39,   6,  67, 159,   5,  11,   6,  67, 637,   5,  16,\n",
              "            6,  68, 664,   5,  16,   8,  39,   6,  68, 177,   5,  16,   8,  11,\n",
              "            6,   2]])]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(ex_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf807690-a8dd-4f8c-8053-943c60e4e295",
      "metadata": {
        "id": "bf807690-a8dd-4f8c-8053-943c60e4e295"
      },
      "source": [
        "### Model basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0349a372-8a06-4a04-b787-2568dceb87f9",
      "metadata": {
        "id": "0349a372-8a06-4a04-b787-2568dceb87f9"
      },
      "source": [
        "Now we come to the model itself. We will first load it and explore it a bit, and then we will define a nice classifier interface for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "76471758-07c0-42b7-b31e-997dc2cd9bd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "689d2bc2aaa24527b419d8c974e746ba",
            "afa5992605f64c0497f5cb66e4132bf8",
            "36c51e2008154917855bc06d3875f4b7",
            "d65211c844374ed3a4ba41bd661dc215",
            "dd52c09f16534b5e93dbf5d9fe5dfab2",
            "c3d869992817438db8d3653a36aea953",
            "74678011ae4d4dbc83477c52f6c4ad62",
            "111244632b7041e6933e2efb46719ca6",
            "68609997b84a4bf59396a4e1f7cb4579",
            "0dcf8bfa320049ee95a8097615957fd6",
            "cc1093d9d1ec469c8712265bebab2eff",
            "2196fc66a3ef493bb4a54fe631517fb6",
            "67d9c1e6dd8f467f9c7522398e698890",
            "c39f05e3a11348729da9a3e0ed0c08c0",
            "72df332aa5cf434dbb25237c32d7d604",
            "1d812a67cb8145688ff02e0f68854458",
            "5de7087734374d5c9bc93cac4146c88a",
            "3534a36288a942579b40c65cfa1ef6d5",
            "ec176db4feab4191bd2edb02ac8a4efa",
            "01b11c312e444a5c9836bfea8a9f2218",
            "8ad6918382a6442b85504803107a56a4",
            "f8a025cc1b234257ba06ced5da48e89b"
          ]
        },
        "id": "76471758-07c0-42b7-b31e-997dc2cd9bd1",
        "outputId": "d273706d-f4e4-4a4b-c900-0dec83df0f03"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "689d2bc2aaa24527b419d8c974e746ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/5.05k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2196fc66a3ef493bb4a54fe631517fb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/17.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "encdec = EncoderDecoderModel.from_pretrained(f\"ReCOGS/ReCOGS-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a470ef9b-32ed-43f1-85f7-17da743a40b1",
      "metadata": {
        "id": "a470ef9b-32ed-43f1-85f7-17da743a40b1"
      },
      "source": [
        "A single illustrative example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "666df81f-beb3-4a30-b202-1193908b78b2",
      "metadata": {
        "id": "666df81f-beb3-4a30-b202-1193908b78b2"
      },
      "outputs": [],
      "source": [
        "ex_inputs = enc_tokenizer.batch_encode_plus(\n",
        "    [\"A rose was helped by a dog .\"],\n",
        "    return_tensors='pt')\n",
        "\n",
        "ex_outputs = dec_tokenizer.batch_encode_plus(\n",
        "    ['rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND theme ( 7 , 53 ) AND agent ( 7 , 38 )'],\n",
        "    return_tensors='pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eeca365-29b8-42bb-a696-cc9bcb6dec7d",
      "metadata": {
        "id": "0eeca365-29b8-42bb-a696-cc9bcb6dec7d"
      },
      "source": [
        "Here is the forward method. For training, it is vital to have `labels=` here so that the model return a loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f64f13fb-b812-445c-8a31-e76233757a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f64f13fb-b812-445c-8a31-e76233757a4f",
        "outputId": "c0a87b12-3257-432c-d84a-958188bd8904"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "ex_rep = encdec(\n",
        "    ex_inputs['input_ids'],\n",
        "    ex_inputs['attention_mask'],\n",
        "    ex_outputs['input_ids'],\n",
        "    labels=ex_outputs['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "12266de7-a99d-4ec8-9d46-bdb62485495a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12266de7-a99d-4ec8-9d46-bdb62485495a",
        "outputId": "cf22be71-753c-459f-8556-e7da1742784a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_rep.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d934b5a8-dfcb-4355-8355-406ee8d2d164",
      "metadata": {
        "id": "d934b5a8-dfcb-4355-8355-406ee8d2d164"
      },
      "source": [
        "And here is how we will do generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "71339418-1d43-4e3a-a9a1-a4b55be343c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71339418-1d43-4e3a-a9a1-a4b55be343c9",
        "outputId": "2a1ac088-493d-4972-a71d-06deea87d883"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  1,   1, 581,   5,  41,   6,  67, 328,   5,  58,   6,  67, 408,   5,\n",
              "          17,   6,  68, 664,   5,  17,   8,  41,   6,  68, 177,   5,  17,   8,\n",
              "          58,   6,   2]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_gen = encdec.generate(\n",
        "    ex_inputs['input_ids'],\n",
        "    attention_mask=ex_inputs['attention_mask'],\n",
        "    max_new_tokens=512,\n",
        "    eos_token_id=encdec.config.eos_token_id)\n",
        "\n",
        "ex_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "91da0447-d244-4fd0-8a6a-1c5bec561d69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91da0447-d244-4fd0-8a6a-1c5bec561d69",
        "outputId": "186090ad-5a2d-4bc5-f9a1-4c44a8b2a7ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[BOS] [BOS] rose ( 37 ) ; dog ( 52 ) ; help ( 15 ) AND theme ( 15 , 37 ) AND agent ( 15 , 52 ) [EOS]']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_pred = dec_tokenizer.batch_decode(\n",
        "    ex_gen,\n",
        "    skip_special_tokens=False,\n",
        "    # Out tokenizer have this set already, but I am nervous:\n",
        "    clean_up_tokenization_spaces=False)\n",
        "\n",
        "ex_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac10a038-99b9-467c-a86d-ed82e7bd8fdc",
      "metadata": {
        "id": "ac10a038-99b9-467c-a86d-ed82e7bd8fdc"
      },
      "source": [
        "### Model interface"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d70b3db7-b1f5-4fab-84b0-4b96d7ced611",
      "metadata": {
        "id": "d70b3db7-b1f5-4fab-84b0-4b96d7ced611"
      },
      "source": [
        "Okay, finally, the main interface. If you do not plan to train your own models using our code, then you can treat `RecogsModel` as an interface and not worry about these details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b17643dd-35bc-4e38-99e4-a61d47d3ed10",
      "metadata": {
        "id": "b17643dd-35bc-4e38-99e4-a61d47d3ed10"
      },
      "outputs": [],
      "source": [
        "from torch_model_base import TorchModelBase\n",
        "import torch.nn as nn\n",
        "from transformers import EncoderDecoderModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d599c05a-1be6-447c-a931-2cadd1112758",
      "metadata": {
        "id": "d599c05a-1be6-447c-a931-2cadd1112758"
      },
      "source": [
        "As I mentioned above, Hugging Face `EncoderDecoderModel` instances will calculate a loss internally if you provide them with `labels`. Normally, one's optimization loop would need to do this manually. In order to rely on Hugging Face and still use the trainer in `torch_model_base.py`, we define this simple loss that just takes in model outputs and labels and returns `outputs.loss`. The labels argument is present for compatibility; it was already used internally to get the value of `outputs.loss` and so can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "f69d742e-58c2-4993-b6d8-6f18b3d157f2",
      "metadata": {
        "id": "f69d742e-58c2-4993-b6d8-6f18b3d157f2"
      },
      "outputs": [],
      "source": [
        "class RecogsLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.reduction = \"mean\"\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        \"\"\"`labels` is ignored, as it was already used to assign a\n",
        "        value of `outputs.loss`, and that value is all we need.\"\"\"\n",
        "        return outputs.loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd27db42-46d1-436e-8870-70fdd38e1219",
      "metadata": {
        "id": "dd27db42-46d1-436e-8870-70fdd38e1219"
      },
      "source": [
        "Here is a basic `nn.Module`. Its sole purpose is to organize the examples created by our `RecogsDataset` and feed them to the trained `EncoderDecoderModel`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "49dd0d13-41fd-4c9a-b7de-90bd2a7a1840",
      "metadata": {
        "id": "49dd0d13-41fd-4c9a-b7de-90bd2a7a1840"
      },
      "outputs": [],
      "source": [
        "class RecogsModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encdec = EncoderDecoderModel.from_pretrained(\n",
        "            f\"ReCOGS/ReCOGS-model\")\n",
        "\n",
        "    def forward(self, X_pad, X_mask, y_pad, y_mask, labels=None):\n",
        "        outputs = self.encdec(\n",
        "            input_ids=X_pad,\n",
        "            attention_mask=X_mask,\n",
        "            decoder_attention_mask=y_mask,\n",
        "            labels=y_pad)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f996ee6c-ef7c-4f51-b596-a1d69ecc59a2",
      "metadata": {
        "id": "f996ee6c-ef7c-4f51-b596-a1d69ecc59a2"
      },
      "source": [
        "And, at last, our interface. The keyword parameter `initialize=True` is the default because we are initially going to use this just for making predictions, and so we need the instance to establish all its parameters when we initialize it as opposed to waiting to do that when we call `fit` (which we may never do)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "7105b19c-a8b7-44c7-9028-f62936a578b2",
      "metadata": {
        "id": "7105b19c-a8b7-44c7-9028-f62936a578b2"
      },
      "outputs": [],
      "source": [
        "class RecogsModel(TorchModelBase):\n",
        "    def __init__(self, *args,\n",
        "            initialize=True,\n",
        "            enc_vocab_filename=f\"{SRC_DIRNAME}/src_vocab.txt\",\n",
        "            dec_vocab_filename=f\"{SRC_DIRNAME}/tgt_vocab.txt\",\n",
        "            **kwargs):\n",
        "        self.enc_vocab_filename = enc_vocab_filename\n",
        "        self.dec_vocab_filename = dec_vocab_filename\n",
        "        self.enc_tokenizer = get_tokenizer(self.enc_vocab_filename)\n",
        "        self.dec_tokenizer = get_tokenizer(self.dec_vocab_filename)\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss = RecogsLoss()\n",
        "        if initialize:\n",
        "            self.initialize()\n",
        "\n",
        "    def build_graph(self):\n",
        "        return RecogsModule()\n",
        "\n",
        "    def build_dataset(self, X, y=None):\n",
        "        return RecogsDataset(\n",
        "            self.enc_tokenizer, self.dec_tokenizer, X, y=y)\n",
        "\n",
        "    def predict(self, X, device=None):\n",
        "        device = self.device if device is None else torch.device(device)\n",
        "        dataset = self.build_dataset(X)\n",
        "        dataloader = self._build_dataloader(dataset, shuffle=False)\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                X_pad, X_mask = [x.to(device) for x in batch]\n",
        "                outputs = self.model.encdec.generate(\n",
        "                    X_pad,\n",
        "                    attention_mask=X_mask,\n",
        "                    max_new_tokens=512,\n",
        "                    eos_token_id=self.model.encdec.config.eos_token_id)\n",
        "                results = self.dec_tokenizer.batch_decode(\n",
        "                    outputs,\n",
        "                    skip_special_tokens=True,\n",
        "                    clean_up_tokenization_spaces=False)\n",
        "                preds += results\n",
        "        return preds\n",
        "\n",
        "    def score(self, X, y, device=None):\n",
        "        # An overall accuracy score:\n",
        "        preds = self.predict(X, device=device)\n",
        "        vals = [int(recogs_exact_match(gold, pred)) for gold, pred in zip(y, preds)]\n",
        "        return sum(vals) / len(vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "95d30490-b7ce-4efe-85f7-e101e3481454",
      "metadata": {
        "id": "95d30490-b7ce-4efe-85f7-e101e3481454"
      },
      "outputs": [],
      "source": [
        "recogs_model = RecogsModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f41201-b28b-4352-9bcf-b62b9d977af9",
      "metadata": {
        "id": "c5f41201-b28b-4352-9bcf-b62b9d977af9"
      },
      "source": [
        "Predictions for our first to train cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "87b99739-eb29-4876-9248-dd72eff1e926",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87b99739-eb29-4876-9248-dd72eff1e926",
        "outputId": "3e00f2bf-fc8f-4075-930a-19b0f0effb6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Liam ( 15 ) ; box ( 47 ) ; girl ( 35 ) ; hope ( 40 ) AND agent ( 40 , 15 ) AND ccomp ( 40 , 8 ) AND burn ( 8 ) AND theme ( 8 , 47 ) AND agent ( 8 , 35 )',\n",
              " '* donkey ( 48 ) ; * cookie ( 25 ) ; mother ( 50 ) ; lend ( 49 ) AND agent ( 49 , 48 ) AND theme ( 49 , 25 ) AND recipient ( 49 , 50 )']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recogs_model.predict(dataset['dev'].input[: 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "1e5dbaff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e5dbaff",
        "outputId": "523c9f65-b6c9-4a92-ee3d-27386f9f29e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Paula ( 2 ) ; cake ( 53 ) ; closet ( 5 ) ; nmod . in ( 53 , 5 ) AND paint ( 52 ) AND agent ( 52 , 2 ) AND theme ( 52 , 53 )',\n",
              " 'Zoe ( 18 ) ; hippo ( 3 ) ; think ( 29 ) AND agent ( 29 , 18 ) AND ccomp ( 29 , 46 ) AND clean ( 46 ) AND agent ( 46 , 3 )']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recogs_model.predict(dataset['gen'].input[: 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da86e9b3-4281-4c74-92e5-9288f202e881",
      "metadata": {
        "id": "da86e9b3-4281-4c74-92e5-9288f202e881"
      },
      "source": [
        "## Question 2: Exploring predictions [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06170626-679b-4710-a4a2-f444c104f44b",
      "metadata": {
        "id": "06170626-679b-4710-a4a2-f444c104f44b"
      },
      "source": [
        "Now that we are set up to use the model, we can move to Question 2. There is just one final preliminary: for ReCOGs, we want to come as close as possible to assessing systems purely on semantic criteria, as opposed to assessing their ability to predict arbitrary features of logical forms. In particular, we want predictions to be independent of the particular choice of variable names and independent of the order of conjuncts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa31f1aa-26a0-41a6-a01b-0a4fe85e6367",
      "metadata": {
        "id": "fa31f1aa-26a0-41a6-a01b-0a4fe85e6367"
      },
      "source": [
        "### ReCOGS assessment function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9451d8-2e9d-4a3d-943f-0d06e747b12f",
      "metadata": {
        "id": "3e9451d8-2e9d-4a3d-943f-0d06e747b12f"
      },
      "source": [
        "The function `recogs_exact_match` does this. It's a complex function, and so you can ignore its precise implementation details. Here are some illustrative examples to give you a feel for it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "08c49a60-082e-42d0-ac75-0a606fd5a588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08c49a60-082e-42d0-ac75-0a606fd5a588",
        "outputId": "d43af5e6-fcbe-472a-f6eb-5b78dd90c450"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The precise names of bound variables do not matter:\n",
        "\n",
        "recogs_exact_match(\n",
        "    \"dog ( 4 ) AND happy ( 4 )\",\n",
        "    \"dog ( 7 ) AND happy ( 7 ) \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "657bc28c-505b-4247-bcbe-dc49718dca2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "657bc28c-505b-4247-bcbe-dc49718dca2f",
        "outputId": "b0f12abb-4cbc-47e2-ef06-cc48dbed7d37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The order of conjuncts does not matter:\n",
        "\n",
        "recogs_exact_match(\n",
        "    \"dog ( 4 ) AND happy ( 4 )\",\n",
        "    \"happy ( 7 ) AND dog ( 7 )\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a49eb573-2153-4f63-aad1-cb5ac8f2df62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a49eb573-2153-4f63-aad1-cb5ac8f2df62",
        "outputId": "86b2d6af-a8b6-4a17-cd26-0de0ed4e77b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Consistency of variable names does matter:\n",
        "\n",
        "recogs_exact_match(\n",
        "    \"dog ( 4 ) AND happy ( 4 )\",\n",
        "    \"dog ( 4 ) AND happy ( 7 )\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39be2e2c-d1d1-4f44-8ca0-2ee0f23cf3ee",
      "metadata": {
        "id": "39be2e2c-d1d1-4f44-8ca0-2ee0f23cf3ee"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "4f1bf0e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4f1bf0e7",
        "outputId": "ffc7b3d5-bb61-403c-8e4c-9e52bfc2d308"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6cc52770-5e42-4dbd-9641-dc2af6398f82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Paula painted a cake in a closet .</td>\n",
              "      <td>Paula ( 50 ) ; cake ( 49 ) ; closet ( 4 ) ; nm...</td>\n",
              "      <td>prim_to_subj_proper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zoe thought that a hippo cleaned .</td>\n",
              "      <td>Zoe ( 29 ) ; hippo ( 37 ) ; think ( 2 ) AND ag...</td>\n",
              "      <td>only_seen_as_unacc_subj_as_obj_omitted_transit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The princess teleported a cookie to the goose .</td>\n",
              "      <td>* princess ( 20 ) ; cookie ( 52 ) ; * goose ( ...</td>\n",
              "      <td>do_dative_to_pp_dative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A cockroach gave a pretzel to Olivia .</td>\n",
              "      <td>cockroach ( 26 ) ; pretzel ( 41 ) ; Olivia ( 4...</td>\n",
              "      <td>obj_to_subj_common</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The girl hoped that the hippo painted .</td>\n",
              "      <td>* girl ( 11 ) ; * hippo ( 42 ) ; hope ( 7 ) AN...</td>\n",
              "      <td>only_seen_as_unacc_subj_as_obj_omitted_transit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cc52770-5e42-4dbd-9641-dc2af6398f82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cc52770-5e42-4dbd-9641-dc2af6398f82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cc52770-5e42-4dbd-9641-dc2af6398f82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e73e087-f4ad-41ca-9e15-7e592feee103\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e73e087-f4ad-41ca-9e15-7e592feee103')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e73e087-f4ad-41ca-9e15-7e592feee103 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             input  \\\n",
              "0               Paula painted a cake in a closet .   \n",
              "1               Zoe thought that a hippo cleaned .   \n",
              "2  The princess teleported a cookie to the goose .   \n",
              "3           A cockroach gave a pretzel to Olivia .   \n",
              "4          The girl hoped that the hippo painted .   \n",
              "\n",
              "                                              output  \\\n",
              "0  Paula ( 50 ) ; cake ( 49 ) ; closet ( 4 ) ; nm...   \n",
              "1  Zoe ( 29 ) ; hippo ( 37 ) ; think ( 2 ) AND ag...   \n",
              "2  * princess ( 20 ) ; cookie ( 52 ) ; * goose ( ...   \n",
              "3  cockroach ( 26 ) ; pretzel ( 41 ) ; Olivia ( 4...   \n",
              "4  * girl ( 11 ) ; * hippo ( 42 ) ; hope ( 7 ) AN...   \n",
              "\n",
              "                                            category  \n",
              "0                                prim_to_subj_proper  \n",
              "1  only_seen_as_unacc_subj_as_obj_omitted_transit...  \n",
              "2                             do_dative_to_pp_dative  \n",
              "3                                 obj_to_subj_common  \n",
              "4  only_seen_as_unacc_subj_as_obj_omitted_transit...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"gen\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4b83476-d018-4b24-9126-38c3577b68de",
      "metadata": {
        "id": "f4b83476-d018-4b24-9126-38c3577b68de"
      },
      "source": [
        "Your task is to write a utility function to see how well a model does on a specific generalization category in the generalization dataset. The metric is accuracy according to `recogs_exact_match`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "378d7f44-a317-433e-befa-301cdcd16978",
      "metadata": {
        "id": "378d7f44-a317-433e-befa-301cdcd16978"
      },
      "outputs": [],
      "source": [
        "def category_assess(gen_df, model, category):\n",
        "    \"\"\"Assess `model` against the `category` examples in `gen_df`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gen_df: pd.DataFrame\n",
        "        Should be `dataset[\"gen\"]`\n",
        "    model: A `RecogsModel instance\n",
        "    category: str\n",
        "        A string from `gen_df.category`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    `pd.DataFrame` limited to `category` examples and with columns\n",
        "    \"prediction\" and \"correct\" added by this function\n",
        "    \"\"\"\n",
        "    # This line is done for you because of how important it is to\n",
        "    # operate on a copy of the dataframe rather than the original!\n",
        "    cat_df = gen_df[gen_df.category == category].copy()\n",
        "\n",
        "    # Step 1: Add a column called \"prediction\" to `cat_df`. This should\n",
        "    # give the predicted LFs:\n",
        "    ##### YOUR CODE HERE\n",
        "    cat_df[\"prediction\"] = model.predict(cat_df['input'])\n",
        "\n",
        "    # Step 2: Add a column \"correct\" that says whether the prediction\n",
        "    # and the gold output are the same. Must use `recogs_exact_match`.\n",
        "    ##### YOUR CODE HERE\n",
        "    cat_df[\"correct\"] = cat_df.apply(lambda x: recogs_exact_match(x['prediction'], x['output']), axis=1)\n",
        "\n",
        "\n",
        "    # Step 3: Return the `pd.DataFrame` `cat_df`:\n",
        "    ##### YOUR CODE HERE\n",
        "    return cat_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "14331e44-6eb6-4c87-9930-28d6b0f1506f",
      "metadata": {
        "id": "14331e44-6eb6-4c87-9930-28d6b0f1506f"
      },
      "outputs": [],
      "source": [
        "def test_category_assess(func):\n",
        "    testmod = RecogsModel()\n",
        "    samp_df = dataset['gen'].head(150)\n",
        "    examples = [\n",
        "        (\"active_to_passive\", 0.80),\n",
        "        (\"unacc_to_transitive\", 0.86),\n",
        "        (\"obj_to_subj_proper\", 0.78)\n",
        "    ]\n",
        "    result_df = func(samp_df, testmod, \"active_to_passive\")\n",
        "    if not isinstance(result_df, pd.DataFrame):\n",
        "        print(f\"Error `{func.__name__}`: \"\n",
        "              \"Return value should be a `pd.DataFrame`\")\n",
        "        return\n",
        "    errcount = 0\n",
        "    for colname in (\"input\", \"output\", \"category\", \"prediction\", \"correct\"):\n",
        "        if colname not in result_df.columns:\n",
        "            errcount += 1\n",
        "            print(f\"Error `{func.__name__}`: column '{colname}' is missing\")\n",
        "    if errcount != 0:\n",
        "        return\n",
        "    expected_len = 5\n",
        "    result_len = result_df.shape[0]\n",
        "    if not result_df.shape[0] == expected_len:\n",
        "        print(f\"Error `{func.__name__}`: \"\n",
        "              f\"Expected {expected_len} results, got {result_len}.\")\n",
        "        return\n",
        "    errcount = 0\n",
        "    for cat, expected in examples:\n",
        "        result_df = func(samp_df, testmod, cat)\n",
        "        result = result_df.correct.sum() / result_df.shape[0]\n",
        "        result = round(result, 2)\n",
        "        if result != expected:\n",
        "            errcount += 1\n",
        "            print(f\"Error `{func.__name__}` with category {cat}: \"\n",
        "                  f\"Expected acc {expected}, got {result}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e3a178d8-b45b-411c-8995-3e6869322565",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3a178d8-b45b-411c-8995-3e6869322565",
        "outputId": "527f86be-2e80-49dd-ddbd-8c1f9ada7884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors for `category_assess`\n"
          ]
        }
      ],
      "source": [
        "test_category_assess(category_assess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fcde66-9b8c-4ca6-947b-2bb8a98a3671",
      "metadata": {
        "id": "f3fcde66-9b8c-4ca6-947b-2bb8a98a3671"
      },
      "source": [
        "Question 1 above might lead you to expect that our model will struggle with examples in which proper names appear with totally unfamiliar roles. For that question, you wrote `get_propername_role` to get `(name, role)` pairs from examples and `find_name_roles` to do analyses with that function. We can now run that same analysis on our errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "67a5305d-4144-45a2-91c4-75e64021fa38",
      "metadata": {
        "id": "67a5305d-4144-45a2-91c4-75e64021fa38"
      },
      "outputs": [],
      "source": [
        "gen_df = dataset['gen']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ede22c2d-6fe3-4dbe-ab0d-ababd9d48d7d",
      "metadata": {
        "id": "ede22c2d-6fe3-4dbe-ab0d-ababd9d48d7d"
      },
      "outputs": [],
      "source": [
        "# Depending on your computer, this could take a while. On a relatively\n",
        "# new Apple laptop, it took about 3 minutes. Colab will be much more\n",
        "# variable in the time it takes, depending on what kind of instance\n",
        "# you are running.\n",
        "\n",
        "pred_df = category_assess(gen_df, recogs_model, \"obj_to_subj_proper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dfda72-8d80-4137-9f34-ec39d3e2de95",
      "metadata": {
        "id": "b6dfda72-8d80-4137-9f34-ec39d3e2de95"
      },
      "source": [
        "Extract the errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "974d1a73-a08b-478f-b463-9c079836755b",
      "metadata": {
        "id": "974d1a73-a08b-478f-b463-9c079836755b"
      },
      "outputs": [],
      "source": [
        "err_df = pred_df[pred_df.correct == False]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d38e4376-ce08-417c-abcd-d414cbc8d2c4",
      "metadata": {
        "id": "d38e4376-ce08-417c-abcd-d414cbc8d2c4"
      },
      "source": [
        "Use `find_name_roles` to get the role distribution in the error set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "df67cec8-3e19-4141-93db-0b5e6c5380d2",
      "metadata": {
        "id": "df67cec8-3e19-4141-93db-0b5e6c5380d2"
      },
      "outputs": [],
      "source": [
        "err_roles = find_name_roles(err_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "56f4fbcb-e9ad-4789-9c8c-f0d66af74426",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56f4fbcb-e9ad-4789-9c8c-f0d66af74426",
        "outputId": "40628e59-2d75-4fd0-93e5-05e8c1179b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Charlie', defaultdict(int, {'agent': 64})),\n",
              " ('Ava', defaultdict(int, {'agent': 1})),\n",
              " ('Skylar', defaultdict(int, {'recipient': 1}))]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(err_roles.items(), key=lambda x: len(x[1]))[: 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5ab221a-f50d-42af-a4ec-c59fcd7eef31",
      "metadata": {
        "id": "f5ab221a-f50d-42af-a4ec-c59fcd7eef31"
      },
      "source": [
        "It's our old friend Charlie – in training, always a theme; in the generalization tests, always an agent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a19b17-f58a-4a40-a07a-71f362dd33d1",
      "metadata": {
        "id": "e7a19b17-f58a-4a40-a07a-71f362dd33d1"
      },
      "source": [
        "## Question 3: In-context learning with DSP [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9489b4a-849d-4b00-835a-a5a6cc6f61d5",
      "metadata": {
        "id": "c9489b4a-849d-4b00-835a-a5a6cc6f61d5"
      },
      "source": [
        "For this question, we are going to switch gears, from using our trained ReCOGS model to seeing whether we can get traction on this problem using only in-context learning. This question is meant to be very straightforward – our sole goal is to get you to the point where you have a working DSP program that you can build on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e9a648-1535-4f31-945f-1488a5883a70",
      "metadata": {
        "id": "c7e9a648-1535-4f31-945f-1488a5883a70"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ae6c14-4aab-41c3-9d12-177c5de38a09",
      "metadata": {
        "id": "99ae6c14-4aab-41c3-9d12-177c5de38a09"
      },
      "source": [
        "Standard set-up for DSP, but we don't need a retriever:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4148343-7182-4e75-be98-f40481e8f4d4",
      "metadata": {
        "id": "e4148343-7182-4e75-be98-f40481e8f4d4"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "from datasets import load_dataset\n",
        "import openai\n",
        "import os\n",
        "import dsp\n",
        "\n",
        "root_path = '.'\n",
        "\n",
        "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
        "\n",
        "openai_key = os.getenv('OPENAI_API_KEY')  # or replace with your API key (optional)\n",
        "\n",
        "cohere_key = 'HdUFD99vS5fdVG0k0tFFEVWvzyuT1O0OIWr5sCs3'  # or replace with your API key (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b8932c-2916-4d35-b05f-533713414c0d",
      "metadata": {
        "id": "31b8932c-2916-4d35-b05f-533713414c0d"
      },
      "source": [
        "Our language model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d1d1d00-4589-45d3-86f3-d6c1b81e8eb1",
      "metadata": {
        "id": "1d1d1d00-4589-45d3-86f3-d6c1b81e8eb1"
      },
      "outputs": [],
      "source": [
        "# Options for Cohere: command-medium-nightly, command-xlarge-nightly\n",
        "lm = dsp.Cohere(model='command-xlarge-nightly', api_key=cohere_key)\n",
        "\n",
        "# Options for OpenAI:\n",
        "# [d[\"root\"] for d in openai.Model.list()[\"data\"]]\n",
        "# lm = dsp.GPT3(model='text-davinci-001', api_key=openai_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7338f9bd-6f4d-4131-bd35-efadd6e2a72e",
      "metadata": {
        "id": "7338f9bd-6f4d-4131-bd35-efadd6e2a72e"
      },
      "source": [
        "DSP settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e2cbc2-60bd-4893-8de0-5ef2ad3950f6",
      "metadata": {
        "id": "18e2cbc2-60bd-4893-8de0-5ef2ad3950f6"
      },
      "outputs": [],
      "source": [
        "dsp.settings.configure(lm=lm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "840dbd4b-7652-4bb8-bafb-c38bd752c10e",
      "metadata": {
        "id": "840dbd4b-7652-4bb8-bafb-c38bd752c10e"
      },
      "source": [
        "### Train examples in DSP format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80ceb9c5-183e-45f0-9f1b-3783b334053c",
      "metadata": {
        "id": "80ceb9c5-183e-45f0-9f1b-3783b334053c"
      },
      "source": [
        "This will convert the train set into a list of `dsp.Example` instances to use for demonstrations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a145a809-6cc7-4711-aa94-850fd1383ea1",
      "metadata": {
        "id": "a145a809-6cc7-4711-aa94-850fd1383ea1"
      },
      "outputs": [],
      "source": [
        "dsp_recogs_train = [dsp.Example(input=row['input'], output=row['output'])\n",
        "                    for _, row in dataset['train'].iterrows()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ac35f2a-9b07-4b0c-bab4-1e4e022f5b03",
      "metadata": {
        "id": "2ac35f2a-9b07-4b0c-bab4-1e4e022f5b03"
      },
      "source": [
        "### Basic template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7860e77a-5799-4975-9b6a-50373aeb743f",
      "metadata": {
        "id": "7860e77a-5799-4975-9b6a-50373aeb743f"
      },
      "outputs": [],
      "source": [
        "Input = dsp.Type(\n",
        "    prefix=\"Input:\",\n",
        "    desc=\"${the sentence to be translated}\")\n",
        "\n",
        "Output = dsp.Type(\n",
        "    prefix=\"Output:\",\n",
        "    desc=\"${a logical form}\",\n",
        "    format=dsp.format_answers)\n",
        "\n",
        "cogs_template = dsp.Template(\n",
        "    instructions=\"Translate sentences into logical forms.\",\n",
        "    input=Input(),\n",
        "    output=Output())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3ff4b52-fa07-4ea8-96c7-bfa91303ebf9",
      "metadata": {
        "id": "f3ff4b52-fa07-4ea8-96c7-bfa91303ebf9"
      },
      "source": [
        "Quick illustration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d130f3-55f6-4e50-875d-bac368405ad9",
      "metadata": {
        "id": "00d130f3-55f6-4e50-875d-bac368405ad9",
        "outputId": "b36ef635-6d1b-4523-9b19-1856302db2b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translate sentences into logical forms.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Input: ${the sentence to be translated}\n",
            "Output: ${a logical form}\n",
            "\n",
            "---\n",
            "\n",
            "Input: A cake was painted by Mason .\n",
            "Output: cake ( 30 ) ; Mason ( 40 ) ; paint ( 22 ) AND theme ( 22 , 30 ) AND agent ( 22 , 40 )\n",
            "\n",
            "Input: The boy painted a rose .\n",
            "Output: * boy ( 36 ) ; rose ( 20 ) ; paint ( 43 ) AND agent ( 43 , 36 ) AND theme ( 43 , 20 )\n",
            "\n",
            "Input: A rose was helped by a dog .\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "ex = dsp.Example(\n",
        "    input=dataset['train'].input[0],\n",
        "    demos=dsp.sample(dsp_recogs_train, k=2))\n",
        "\n",
        "print(cogs_template(ex))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa596d1b-61ed-4c5d-b3af-dceb1c0861f8",
      "metadata": {
        "id": "fa596d1b-61ed-4c5d-b3af-dceb1c0861f8"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c27587-4c06-453d-9579-6429a762df8e",
      "metadata": {
        "id": "c8c27587-4c06-453d-9579-6429a762df8e"
      },
      "source": [
        "Your task is just to complete the following very basic DSP program. The steps are laid out for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a45b47-e2ab-4a5d-a0b3-b5507c4d4f10",
      "metadata": {
        "id": "11a45b47-e2ab-4a5d-a0b3-b5507c4d4f10"
      },
      "outputs": [],
      "source": [
        "@dsp.transformation\n",
        "def recogs_dsp(example, train=dsp_recogs_train, k=2):\n",
        "    pass\n",
        "    # Step 1: Sample k train cases and add them to the `demos`\n",
        "    # attribute of `example`:\n",
        "    ##### YOUR CODE HERE\n",
        "    example.demos = dsp.sample(train, k=k)\n",
        "\n",
        "\n",
        "    # Run your program using `cogs_template`:\n",
        "    ##### YOUR CODE HERE\n",
        "    _, completions = dsp.generate(cogs_template)(example, stage='qa')\n",
        "\n",
        "\n",
        "    # Return the `dsp.Completions`:\n",
        "    ##### YOUR CODE HERE\n",
        "    return completions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82299806-3fe7-4b96-ba74-f1a4624c4654",
      "metadata": {
        "id": "82299806-3fe7-4b96-ba74-f1a4624c4654"
      },
      "source": [
        "A quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4dc1175-8a2d-4de4-a71c-1abb61d78f6e",
      "metadata": {
        "id": "e4dc1175-8a2d-4de4-a71c-1abb61d78f6e"
      },
      "outputs": [],
      "source": [
        "def test_recogs_dsp(func):\n",
        "    k = 3\n",
        "    ex = dsp.Example(input=\"Q0\", output=[\"A0\"])\n",
        "    train = [\n",
        "        dsp.Example(input=\"Q1\", output=[\"A1\"]),\n",
        "        dsp.Example(input=\"Q2\", output=[\"A2\"]),\n",
        "        dsp.Example(input=\"Q3\", output=[\"A3\"]),\n",
        "        dsp.Example(input=\"Q4\", output=[\"A4\"])]\n",
        "    compl = func(ex, train=train, k=k)\n",
        "    errcount = 0\n",
        "    # Check the LM was used as expected:\n",
        "    if len(compl.data) != 1:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: Unexpected LM output.\")\n",
        "    data = compl.data[0]\n",
        "    # Check that the right number of demos was used:\n",
        "    demos = data['demos']\n",
        "    if len(demos) != k:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Unexpected demo count: {len(demos)}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab096a5-a7ee-4fd0-941a-7f70c403f4d0",
      "metadata": {
        "id": "4ab096a5-a7ee-4fd0-941a-7f70c403f4d0",
        "outputId": "37ad7fe0-e4d1-4d42-f1e4-b19d4b6c3c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backing off 0.8 seconds after 1 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 0.5 seconds after 2 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 0.5 seconds after 3 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 1.2 seconds after 4 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 2.3 seconds after 5 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 17.6 seconds after 6 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 19.6 seconds after 7 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 63.3 seconds after 8 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 234.7 seconds after 9 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 25.2 seconds after 10 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n",
            "Backing off 593.5 seconds after 11 tries calling function <function Cohere.request at 0x7f85f7effb80> with kwargs {'num_generations': 1}\n"
          ]
        },
        {
          "ename": "CohereAPIError",
          "evalue": "You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCohereAPIError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[154], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_recogs_dsp(recogs_dsp)\n",
            "Cell \u001b[0;32mIn[153], line 9\u001b[0m, in \u001b[0;36mtest_recogs_dsp\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m      3\u001b[0m ex \u001b[39m=\u001b[39m dsp\u001b[39m.\u001b[39mExample(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ0\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mA0\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m train \u001b[39m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     dsp\u001b[39m.\u001b[39mExample(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ1\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mA1\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m      6\u001b[0m     dsp\u001b[39m.\u001b[39mExample(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ2\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mA2\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m      7\u001b[0m     dsp\u001b[39m.\u001b[39mExample(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ3\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mA3\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m      8\u001b[0m     dsp\u001b[39m.\u001b[39mExample(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQ4\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mA4\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[0;32m----> 9\u001b[0m compl \u001b[39m=\u001b[39m func(ex, train\u001b[39m=\u001b[39;49mtrain, k\u001b[39m=\u001b[39;49mk)\n\u001b[1;32m     10\u001b[0m errcount \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Check the LM was used as expected:\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/dsp/primitives/primitives.py:19\u001b[0m, in \u001b[0;36mshallow_copy_example_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m args \u001b[39m=\u001b[39m [dsp\u001b[39m.\u001b[39mExample(arg) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, dsp\u001b[39m.\u001b[39mExample) \u001b[39melse\u001b[39;00m arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[1;32m     18\u001b[0m kwargs \u001b[39m=\u001b[39m {key: dsp\u001b[39m.\u001b[39mExample(value) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, dsp\u001b[39m.\u001b[39mExample) \u001b[39melse\u001b[39;00m value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "Cell \u001b[0;32mIn[152], line 12\u001b[0m, in \u001b[0;36mrecogs_dsp\u001b[0;34m(example, train, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m example\u001b[39m.\u001b[39mdemos \u001b[39m=\u001b[39m dsp\u001b[39m.\u001b[39msample(train, k\u001b[39m=\u001b[39mk)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Run your program using `cogs_template`:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m##### YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m _, completions \u001b[39m=\u001b[39m dsp\u001b[39m.\u001b[39;49mgenerate(cogs_template)(example, stage\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mqa\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Return the `dsp.Completions`:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m##### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m completions\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/dsp/primitives/predict.py:77\u001b[0m, in \u001b[0;36m_generate.<locals>.do_generate\u001b[0;34m(example, stage, max_depth, original_example)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m# Generate and extract the fields.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m prompt \u001b[39m=\u001b[39m template(example)\n\u001b[0;32m---> 77\u001b[0m completions: \u001b[39mlist\u001b[39m[\u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m generator(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m completions: \u001b[39mlist\u001b[39m[Example] \u001b[39m=\u001b[39m [template\u001b[39m.\u001b[39mextract(example, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m completions]\n\u001b[1;32m     80\u001b[0m \u001b[39m# Find the completions that are most complete.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/dsp/modules/cohere.py:128\u001b[0m, in \u001b[0;36mCohere.__call__\u001b[0;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_generations\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_num_generations\n\u001b[0;32m--> 128\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    129\u001b[0m     choices\u001b[39m.\u001b[39mextend(response\u001b[39m.\u001b[39mgenerations)\n\u001b[1;32m    130\u001b[0m completions \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m choices]\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39melapsed\u001b[39m\u001b[39m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[39m=\u001b[39m (tries \u001b[39m==\u001b[39m max_tries_value)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/dsp/modules/cohere.py:102\u001b[0m, in \u001b[0;36mCohere.request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@backoff\u001b[39m\u001b[39m.\u001b[39mon_exception(\n\u001b[1;32m     94\u001b[0m     backoff\u001b[39m.\u001b[39mexpo,\n\u001b[1;32m     95\u001b[0m     (cohere_api_error),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    101\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Handles retrieval of completions from Cohere whilst handling API errors\"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_request(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/dsp/modules/cohere.py:81\u001b[0m, in \u001b[0;36mCohere.basic_request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m raw_kwargs \u001b[39m=\u001b[39m kwargs\n\u001b[1;32m     75\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m     76\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs,\n\u001b[1;32m     77\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_sequences,\n\u001b[1;32m     78\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[1;32m     79\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     80\u001b[0m }\n\u001b[0;32m---> 81\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mco\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     83\u001b[0m history \u001b[39m=\u001b[39m {\n\u001b[1;32m     84\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[1;32m     85\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m: response,\n\u001b[1;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m\"\u001b[39m: kwargs,\n\u001b[1;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mraw_kwargs\u001b[39m\u001b[39m\"\u001b[39m: raw_kwargs,\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mappend(history)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/cohere/client.py:221\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, prompt, prompt_vars, model, preset, num_generations, max_tokens, temperature, k, p, frequency_penalty, presence_penalty, end_sequences, stop_sequences, return_likelihoods, truncate, logit_bias, stream)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mSee https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m        >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m json_body \u001b[39m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m }\n\u001b[0;32m--> 221\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(cohere\u001b[39m.\u001b[39;49mGENERATE_URL, json\u001b[39m=\u001b[39;49mjson_body, stream\u001b[39m=\u001b[39;49mstream)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m StreamingGenerations(response)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/cohere/client.py:853\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, endpoint, json, files, method, stream, params)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[39mexcept\u001b[39;00m jsonlib\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mJSONDecodeError:  \u001b[39m# CohereAPIError will capture status\u001b[39;00m\n\u001b[1;32m    851\u001b[0m         \u001b[39mraise\u001b[39;00m CohereAPIError\u001b[39m.\u001b[39mfrom_response(response, message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to decode json body: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 853\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_response(json_response, response\u001b[39m.\u001b[39;49mheaders, response\u001b[39m.\u001b[39;49mstatus_code)\n\u001b[1;32m    854\u001b[0m \u001b[39mreturn\u001b[39;00m json_response\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/cohere/client.py:795\u001b[0m, in \u001b[0;36mClient._check_response\u001b[0;34m(self, json_response, headers, status_code)\u001b[0m\n\u001b[1;32m    793\u001b[0m     logger\u001b[39m.\u001b[39mwarning(headers[\u001b[39m\"\u001b[39m\u001b[39mX-API-Warning\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    794\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m json_response:  \u001b[39m# has errors\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m     \u001b[39mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    796\u001b[0m         message\u001b[39m=\u001b[39mjson_response[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    797\u001b[0m         http_status\u001b[39m=\u001b[39mstatus_code,\n\u001b[1;32m    798\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    799\u001b[0m     )\n\u001b[1;32m    800\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m400\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m status_code \u001b[39m<\u001b[39m \u001b[39m500\u001b[39m:\n\u001b[1;32m    801\u001b[0m     \u001b[39mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    802\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected client error (status \u001b[39m\u001b[39m{\u001b[39;00mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m{\u001b[39;00mjson_response\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    803\u001b[0m         http_status\u001b[39m=\u001b[39mstatus_code,\n\u001b[1;32m    804\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    805\u001b[0m     )\n",
            "\u001b[0;31mCohereAPIError\u001b[0m: You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.ai/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions"
          ]
        }
      ],
      "source": [
        "test_recogs_dsp(recogs_dsp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cf46aa-3881-4a3d-8592-7c5292786f23",
      "metadata": {
        "id": "b3cf46aa-3881-4a3d-8592-7c5292786f23"
      },
      "outputs": [],
      "source": [
        "recogs_dsp(ex).output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0eaa937-771e-4202-88a7-c6e708a3d3ad",
      "metadata": {
        "id": "b0eaa937-771e-4202-88a7-c6e708a3d3ad"
      },
      "source": [
        "### Optional assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ca366b-aa51-4d81-b400-c6c9500eb482",
      "metadata": {
        "id": "b8ca366b-aa51-4d81-b400-c6c9500eb482"
      },
      "source": [
        "Here we sample 10 dev cases for a small evaluation. If you adapt this code, remember to use `recogs_exact_match` so that you aren't unfairly penalized for conjunct order or varible name differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a20ae08-86ef-40da-a963-69a7333647ce",
      "metadata": {
        "id": "6a20ae08-86ef-40da-a963-69a7333647ce"
      },
      "outputs": [],
      "source": [
        "ssamp = dataset['dev'].sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268a2271-8a65-4355-8885-6f2bc214ff91",
      "metadata": {
        "id": "268a2271-8a65-4355-8885-6f2bc214ff91"
      },
      "outputs": [],
      "source": [
        "ssamp['prediction'] = ssamp.input.apply(\n",
        "    lambda x: recogs_dsp(dsp.Example(input=x)).output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9415ce6-a4e2-4b03-81dd-5ad85e0de78f",
      "metadata": {
        "id": "d9415ce6-a4e2-4b03-81dd-5ad85e0de78f"
      },
      "outputs": [],
      "source": [
        "ssamp['correct'] = ssamp.apply(\n",
        "    lambda row: recogs_exact_match(row['output'], row['prediction']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa9e743e-5941-47dd-8953-cc3b302a314a",
      "metadata": {
        "id": "aa9e743e-5941-47dd-8953-cc3b302a314a"
      },
      "outputs": [],
      "source": [
        "ssamp['correct'].sum() / ssamp.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294287-5808-4eb7-ac2d-19bd0b660bd2",
      "metadata": {
        "id": "c5294287-5808-4eb7-ac2d-19bd0b660bd2"
      },
      "source": [
        "A random example to see what's going on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "909fa032-f559-4971-94a8-16c7eba054d8",
      "metadata": {
        "id": "909fa032-f559-4971-94a8-16c7eba054d8"
      },
      "outputs": [],
      "source": [
        "ssamp.sample(1).to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f3cede",
      "metadata": {
        "id": "d0f3cede"
      },
      "outputs": [],
      "source": [
        "train_roles = find_name_roles(dataset['train'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374aadbf",
      "metadata": {
        "id": "374aadbf",
        "outputId": "9177518e-4d71-4a33-d915-7a30a0dc1854"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Emma',\n",
              "  defaultdict(int, {'agent': 18640, 'recipient': 8465, 'theme': 1465})),\n",
              " ('Evelyn', defaultdict(int, {'agent': 570, 'recipient': 165, 'theme': 70})),\n",
              " ('Charlotte',\n",
              "  defaultdict(int, {'agent': 1125, 'recipient': 535, 'theme': 85}))]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(train_roles.items(), key=lambda x: len(x))[: 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5faf84b5-af29-4a55-8f83-6f71fdb1c054",
      "metadata": {
        "id": "5faf84b5-af29-4a55-8f83-6f71fdb1c054"
      },
      "source": [
        "## Question 4: Original System [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfa81ab-c4a1-4f4e-9d50-d223f81c90a6",
      "metadata": {
        "id": "7cfa81ab-c4a1-4f4e-9d50-d223f81c90a6"
      },
      "source": [
        "For your original system, you can do anything at all. The only constraint (repeated from above):\n",
        "\n",
        "__You cannot train your system on any examples from `dataset[\"gen\"]`, nor can the output representations from those examples be included in any prompts used for in-context learning.__\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "b9b50392-e869-4315-bb2f-09b76b8000ae",
      "metadata": {
        "id": "b9b50392-e869-4315-bb2f-09b76b8000ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "683caafd7f9b45a99054d952c5a87eb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96ca85c270cd487f9d2bbfc33adaae2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "550acf64953b486782a84766c18170b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file spiece.model from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/spiece.model\n",
            "loading file tokenizer.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--t5-small/snapshots/df1b051c49625cf57a3d0d8d3863ed4d13564fe4/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " epoch 1: batch 1 of 1895"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " epoch 1: batch 2 of 1895"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " epoch 1: batch 3 of 1895"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " epoch 1: batch 4 of 1895"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " epoch 1: batch 5 of 1895"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[178], line 101\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[39mreturn\u001b[39;00m T5RecogsModule()\n\u001b[1;32m     93\u001b[0m recogs_ff \u001b[39m=\u001b[39m T5RecogsModel(\n\u001b[1;32m     94\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m     95\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     optimizer_class\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam,\n\u001b[1;32m    100\u001b[0m     eta\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m _ \u001b[39m=\u001b[39m recogs_ff\u001b[39m.\u001b[39;49mfit(full_dataset_train\u001b[39m.\u001b[39;49minput, full_dataset_train\u001b[39m.\u001b[39;49moutput)\n",
            "File \u001b[0;32m~/courses/cs224u/torch_model_base.py:357\u001b[0m, in \u001b[0;36mTorchModelBase.fit\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    354\u001b[0m X_batch \u001b[39m=\u001b[39m batch[: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    355\u001b[0m y_batch \u001b[39m=\u001b[39m batch[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 357\u001b[0m batch_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49mX_batch)\n\u001b[1;32m    359\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(batch_preds, y_batch)\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    362\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mreduction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[178], line 77\u001b[0m, in \u001b[0;36mT5RecogsModule.forward\u001b[0;34m(self, X_pad, X_mask, y_pad, y_mask, labels)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X_pad, X_mask, y_pad, y_mask, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 77\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencdec(\n\u001b[1;32m     78\u001b[0m         input_ids\u001b[39m=\u001b[39;49mX_pad,\n\u001b[1;32m     79\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mX_mask,\n\u001b[1;32m     80\u001b[0m         decoder_attention_mask\u001b[39m=\u001b[39;49my_mask,\n\u001b[1;32m     81\u001b[0m         labels\u001b[39m=\u001b[39;49my_pad)\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1663\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1662\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1663\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1664\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1665\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1666\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1667\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1668\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1669\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1670\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1671\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1672\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1673\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1674\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1675\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1676\u001b[0m )\n\u001b[1;32m   1678\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1680\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1055\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1043\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1044\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1056\u001b[0m         hidden_states,\n\u001b[1;32m   1057\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1058\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1059\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1060\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1061\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1062\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1063\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1064\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1065\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1066\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1067\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:739\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    736\u001b[0m     attention_outputs \u001b[39m=\u001b[39m attention_outputs \u001b[39m+\u001b[39m cross_attention_outputs[\u001b[39m2\u001b[39m:]\n\u001b[1;32m    738\u001b[0m \u001b[39m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m](hidden_states)\n\u001b[1;32m    741\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[39mif\u001b[39;00m hidden_states\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16 \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39misinf(hidden_states)\u001b[39m.\u001b[39many():\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:337\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    335\u001b[0m forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m    336\u001b[0m forwarded_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDenseReluDense(forwarded_states)\n\u001b[0;32m--> 337\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(forwarded_states)\n\u001b[1;32m    338\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
            "File \u001b[0;32m~/miniconda3/envs/nlu/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "#\n",
        "# For my system, I decided to try and make the data generalize to more complicated names to also give it more examples.\n",
        "# To do so, I generated 1000 random names using an online tool (https://1000randomnames.com/). I use these to generate more examples, by replacing the names in the original dataset with the random names.\n",
        "# I also generated random nouns.\n",
        "# I left those in this drive : https://docs.google.com/spreadsheets/d/1wAfJSCeZfb9B2TOY61TnuXSB-QPD16r2sKsujPWVKqc/edit#gid=0\n",
        "# I'm downloading them here just to not flood the cell with the list of names.\n",
        "# I used the generated nouns to augment the data a bit with new examples, takign 75000 examples from the train set and replacing them with random combinations\n",
        "# I purposefully added some \"weird\" examples by replacing things like \"Joan threw an apple to Jack\" by \"Nick Bandso threw Joanna Jones to Rick Astley\"\n",
        "# This is to try not overfit too much to the train set and to try and generalize to more complicated names and encounters\n",
        "# I also used the T5 model as base\n",
        "import random\n",
        "import re\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "random_names = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1wAfJSCeZfb9B2TOY61TnuXSB-QPD16r2sKsujPWVKqc/gviz/tq?tqx=out:csv&sheet=names\")\n",
        "random_nouns = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1wAfJSCeZfb9B2TOY61TnuXSB-QPD16r2sKsujPWVKqc/gviz/tq?tqx=out:csv&sheet=nouns\")\n",
        "new_ds = dataset[\"train\"].sample(75000)\n",
        "new_ds[\"original_input\"] = new_ds[\"input\"]\n",
        "new_ds[\"original_output\"] = new_ds[\"output\"]\n",
        "\n",
        "def randomize_names(input, output):\n",
        "    # get proper names\n",
        "    name_pattern = r\"([A-Z][a-z]+) \\( (\\d+) \\)\"\n",
        "    # get stuff like \"* cookie (20)\"\n",
        "    star_pattern = r\"(\\* [a-z]+) \\( (\\d+) \\)\"\n",
        "\n",
        "    # generate a random name\n",
        "    proper_names = re.findall(name_pattern, output)\n",
        "    star_names = re.findall(star_pattern, output)\n",
        "\n",
        "    # If there was nor a proper nor a common name subject\n",
        "    if len(proper_names) == 0 and len(star_names) == 0:\n",
        "        return input, output\n",
        "\n",
        "    # If there is a proper name, randomize it\n",
        "    for name in proper_names:\n",
        "        random_name = random_names.sample(1)[\"NAME\"].values[0]\n",
        "\n",
        "        output = output.replace(name[0], random_name)\n",
        "        input = input.replace(name[0], random_name)\n",
        "\n",
        "    for match in star_names:\n",
        "        # to add some \"weird\" data and reduce overfitting, sometimes we will replace nouns by nouns, sometimes by proper names\n",
        "        # half the time use a name\n",
        "        if random.random() > 0.5:\n",
        "            random_name = random_names.sample(1)[\"NAME\"].values[0]\n",
        "            name = match[0].replace(\"* \", \"\")\n",
        "            output = output.replace(match[0], random_name)\n",
        "            # here, we need to replace the previous determinant on the common name, for example \"the cat\" -> Emma\n",
        "            input = re.sub(r\"[a-zA-Z]+ \" + name, random_name, input)\n",
        "        # the rest of the time use a noun. The determiner is not necessarily the correct one, but I don't actually think that matters\n",
        "        else:\n",
        "            random_noun = random_nouns.sample(1)[\"NOUN\"].values[0]\n",
        "            name = match[0].replace(\"* \", \"\")\n",
        "            output = output.replace(name, random_noun)\n",
        "            input = input.replace(name, random_noun)\n",
        "\n",
        "    return input, output\n",
        "\n",
        "new_ds[[\"input\", \"output\"]] = new_ds[[\"input\", \"output\"]].apply(lambda x: randomize_names(x[\"input\"], x[\"output\"]), axis=1, result_type=\"expand\")\n",
        "full_dataset_train = pd.concat([dataset[\"train\"], new_ds])\n",
        "\n",
        "class T5RecogsModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encdec = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "    def forward(self, X_pad, X_mask, y_pad, y_mask, labels=None):\n",
        "        outputs = self.encdec(\n",
        "            input_ids=X_pad,\n",
        "            attention_mask=X_mask,\n",
        "            decoder_attention_mask=y_mask,\n",
        "            labels=y_pad)\n",
        "        return outputs\n",
        "\n",
        "class T5RecogsModel(RecogsModel):\n",
        "    def __init__(self, *args, initialize=True, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.enc_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "        self.dec_tokenizer = self.enc_tokenizer\n",
        "\n",
        "    def build_graph(self):\n",
        "        return T5RecogsModule()\n",
        "    \n",
        "recogs_ff = T5RecogsModel(\n",
        "    batch_size=100,\n",
        "    gradient_accumulation_steps=20,\n",
        "    max_iter=10,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=1,\n",
        "    optimizer_class=torch.optim.Adam,\n",
        "    eta=0.00001)\n",
        "_ = recogs_ff.fit(full_dataset_train.input, full_dataset_train.output)\n",
        "# STOP COMMENT: Please do not remove this comment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "8ec6ca8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "8ec6ca8f",
        "outputId": "9ba22f2e-fa9a-4e7d-8325-8f0433735f76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-54234d43-845c-4765-b3dc-a2dd3e838c89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A rose was helped by a dog .</td>\n",
              "      <td>rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND them...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sailor dusted a boy .</td>\n",
              "      <td>* sailor ( 48 ) ; boy ( 53 ) ; dust ( 10 ) AND...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emma rolled a teacher .</td>\n",
              "      <td>Emma ( 17 ) ; teacher ( 50 ) ; roll ( 39 ) AND...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Evelyn rolled the girl .</td>\n",
              "      <td>Evelyn ( 46 ) ; * girl ( 16 ) ; roll ( 21 ) AN...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cake was forwarded to Levi by Charlotte .</td>\n",
              "      <td>cake ( 5 ) ; Levi ( 34 ) ; Charlotte ( 33 ) ; ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The captain ate .</td>\n",
              "      <td>* captain ( 56 ) ; eat ( 46 ) AND agent ( 46 ,...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The girl needed to cook .</td>\n",
              "      <td>* girl ( 51 ) ; need ( 14 ) AND agent ( 14 , 5...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A cake rolled .</td>\n",
              "      <td>cake ( 33 ) ; roll ( 39 ) AND theme ( 39 , 33 )</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The cookie was passed to Emma .</td>\n",
              "      <td>* cookie ( 20 ) ; Emma ( 16 ) ; pass ( 28 ) AN...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Emma ate the ring beside a bed .</td>\n",
              "      <td>Emma ( 10 ) ; * ring ( 24 ) ; bed ( 0 ) ; nmod...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54234d43-845c-4765-b3dc-a2dd3e838c89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54234d43-845c-4765-b3dc-a2dd3e838c89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54234d43-845c-4765-b3dc-a2dd3e838c89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b112fe7-8249-400f-93e3-ee3aac3ce2f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b112fe7-8249-400f-93e3-ee3aac3ce2f1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b112fe7-8249-400f-93e3-ee3aac3ce2f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         input  \\\n",
              "0                 A rose was helped by a dog .   \n",
              "1                    The sailor dusted a boy .   \n",
              "2                      Emma rolled a teacher .   \n",
              "3                     Evelyn rolled the girl .   \n",
              "4  A cake was forwarded to Levi by Charlotte .   \n",
              "5                            The captain ate .   \n",
              "6                    The girl needed to cook .   \n",
              "7                              A cake rolled .   \n",
              "8              The cookie was passed to Emma .   \n",
              "9             Emma ate the ring beside a bed .   \n",
              "\n",
              "                                              output         category  \n",
              "0  rose ( 53 ) ; dog ( 38 ) ; help ( 7 ) AND them...  in_distribution  \n",
              "1  * sailor ( 48 ) ; boy ( 53 ) ; dust ( 10 ) AND...  in_distribution  \n",
              "2  Emma ( 17 ) ; teacher ( 50 ) ; roll ( 39 ) AND...  in_distribution  \n",
              "3  Evelyn ( 46 ) ; * girl ( 16 ) ; roll ( 21 ) AN...  in_distribution  \n",
              "4  cake ( 5 ) ; Levi ( 34 ) ; Charlotte ( 33 ) ; ...  in_distribution  \n",
              "5  * captain ( 56 ) ; eat ( 46 ) AND agent ( 46 ,...  in_distribution  \n",
              "6  * girl ( 51 ) ; need ( 14 ) AND agent ( 14 , 5...  in_distribution  \n",
              "7    cake ( 33 ) ; roll ( 39 ) AND theme ( 39 , 33 )  in_distribution  \n",
              "8  * cookie ( 20 ) ; Emma ( 16 ) ; pass ( 28 ) AN...  in_distribution  \n",
              "9  Emma ( 10 ) ; * ring ( 24 ) ; bed ( 0 ) ; nmod...  in_distribution  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "29eb7555",
      "metadata": {
        "id": "29eb7555"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "new_ds = dataset[\"train\"].sample(75000)\n",
        "new_ds[\"original_input\"] = new_ds[\"input\"]\n",
        "new_ds[\"original_output\"] = new_ds[\"output\"]\n",
        "\n",
        "def randomize_names(input, output):\n",
        "    # get proper names\n",
        "    name_pattern = r\"([A-Z][a-z]+) \\( (\\d+) \\)\"\n",
        "    # get stuff like \"* cookie (20)\"\n",
        "    star_pattern = r\"(\\* [a-z]+) \\( (\\d+) \\)\"\n",
        "\n",
        "    # generate a random name\n",
        "    proper_names = re.findall(name_pattern, output)\n",
        "    star_names = re.findall(star_pattern, output)\n",
        "\n",
        "    # If there was nor a proper nor a common name subject\n",
        "    if len(proper_names) == 0 and len(star_names) == 0:\n",
        "        return input, output\n",
        "\n",
        "    # If there is a proper name, randomize it\n",
        "    for name in proper_names:\n",
        "        random_name = random_names.sample(1)[\"NAME\"].values[0]\n",
        "\n",
        "        output = output.replace(name[0], random_name)\n",
        "        input = input.replace(name[0], random_name)\n",
        "\n",
        "    for match in star_names:\n",
        "        # to add some \"weird\" data and reduce overfitting, sometimes we will replace nouns by nouns, sometimes by proper names\n",
        "        # half the time use a name\n",
        "        if random.random() > 0.5:\n",
        "            random_name = random_names.sample(1)[\"NAME\"].values[0]\n",
        "            name = match[0].replace(\"* \", \"\")\n",
        "            output = output.replace(match[0], random_name)\n",
        "            # here, we need to replace the previous determinant on the common name, for example \"the cat\" -> Emma\n",
        "            input = re.sub(r\"[a-zA-Z]+ \" + name, random_name, input)\n",
        "        # the rest of the time use a noun. The determiner is not necessarily the correct one, but I don't actually think that matters\n",
        "        else:\n",
        "            random_noun = random_nouns.sample(1)[\"NOUN\"].values[0]\n",
        "            name = match[0].replace(\"* \", \"\")\n",
        "            output = output.replace(name, random_noun)\n",
        "            input = input.replace(name, random_noun)\n",
        "\n",
        "    return input, output\n",
        "\n",
        "new_ds[[\"input\", \"output\"]] = new_ds[[\"input\", \"output\"]].apply(lambda x: randomize_names(x[\"input\"], x[\"output\"]), axis=1, result_type=\"expand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562e51a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "562e51a7",
        "outputId": "c987f99f-98e2-4c98-957d-022b2842170c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "full_dataset_train = pd.concat([dataset[\"train\"], new_ds])\n",
        "recogs_ff = RecogsModel(\n",
        "    batch_size=100,\n",
        "    gradient_accumulation_steps=20,\n",
        "    max_iter=10,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=1,\n",
        "    optimizer_class=torch.optim.Adam,\n",
        "    eta=0.00001)\n",
        "_ = recogs_ff.fit(full_dataset_train.input, full_dataset_train.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcb4dab-c0a9-4b1c-a556-148d66b2a77a",
      "metadata": {
        "id": "3fcb4dab-c0a9-4b1c-a556-148d66b2a77a"
      },
      "source": [
        "Here are some potential paths – just a few of many options, though!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20adf07-b7f3-4e6f-b172-73cfe781b7a4",
      "metadata": {
        "id": "e20adf07-b7f3-4e6f-b172-73cfe781b7a4"
      },
      "source": [
        "### Option: DSP program\n",
        "\n",
        "This could build on Question 3 very directly. All we have tried ourselves so far is the simple approach from that question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da281ffa-ecf4-4598-bd1f-484153378a18",
      "metadata": {
        "id": "da281ffa-ecf4-4598-bd1f-484153378a18"
      },
      "source": [
        "### Option: Further training of our model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8eb6de7-bab8-4f38-9567-49ea8d47dda7",
      "metadata": {
        "id": "b8eb6de7-bab8-4f38-9567-49ea8d47dda7"
      },
      "source": [
        "This is very easy to do. For example, here we do some training on the first 10 dev examples, and we've exposed some keyword arguments that may be of interest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76cf1b21-8059-4bc2-9cf8-a23b910e8b7f",
      "metadata": {
        "id": "76cf1b21-8059-4bc2-9cf8-a23b910e8b7f",
        "outputId": "f56e136d-00c2-4c8f-dfd8-efa68e1714ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--ReCOGS--ReCOGS-model/snapshots/f3c738eefe8b0b709b046286818c07626c674c3b/config.json\n",
            "Model config EncoderDecoderConfig {\n",
            "  \"_commit_hash\": \"f3c738eefe8b0b709b046286818c07626c674c3b\",\n",
            "  \"_name_or_path\": \"./results_recogs/cogs_pipeline.model.ende_transformer.lf.cogs.glove.False.seed.42/model-last/\",\n",
            "  \"architectures\": [\n",
            "    \"EncoderDecoderModel\"\n",
            "  ],\n",
            "  \"decoder\": {\n",
            "    \"_name_or_path\": \"./model/decoder_config.json\",\n",
            "    \"add_cross_attention\": true,\n",
            "    \"architectures\": [\n",
            "      \"Bert\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": 1,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": 1,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 300,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 512,\n",
            "    \"is_decoder\": true,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"mask_token_id\": 4,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 4,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 2,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_init\": \"random\",\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.26.1\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"unk_token_id\": 3,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 729\n",
            "  },\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"encoder\": {\n",
            "    \"_name_or_path\": \"./model/encoder_config.json\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"Bert\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": 1,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cls_token_id\": 5,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 300,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 512,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"mask_token_id\": 4,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"nsp_token_id\": 7,\n",
            "    \"num_attention_heads\": 4,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 2,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_init\": \"random\",\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"sum_token_id\": 6,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.26.1\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"unk_token_id\": 3,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 762\n",
            "  },\n",
            "  \"eos_token_id\": 2,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"model_type\": \"encoder-decoder\",\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": null\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /Users/pierrecadmanbosse/.cache/huggingface/hub/models--ReCOGS--ReCOGS-model/snapshots/f3c738eefe8b0b709b046286818c07626c674c3b/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
            "\n",
            "All the weights of EncoderDecoderModel were initialized from the model checkpoint at ReCOGS/ReCOGS-model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n",
            "Generation config file not found, using a generation config created from the model config.\n"
          ]
        }
      ],
      "source": [
        "# recogs_ff = RecogsModel(\n",
        "#     batch_size=5,\n",
        "#     gradient_accumulation_steps=20,\n",
        "#     max_iter=100,\n",
        "#     early_stopping=True,\n",
        "#     n_iter_no_change=10,\n",
        "#     optimizer_class=torch.optim.Adam,\n",
        "#     eta=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd269d1-d835-4241-a5b6-0463883a42c4",
      "metadata": {
        "id": "2bd269d1-d835-4241-a5b6-0463883a42c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "58af5ee4-d7e9-4700-8700-0021f11a1e1a",
      "metadata": {
        "id": "58af5ee4-d7e9-4700-8700-0021f11a1e1a"
      },
      "source": [
        "For this, you will want to pay a lot of attention to the optimization-related parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b64ec5e-56dd-4174-96ea-b9574a39ea58",
      "metadata": {
        "id": "6b64ec5e-56dd-4174-96ea-b9574a39ea58"
      },
      "source": [
        "### Option: Using a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d71f245a-c474-4723-a1c8-ea4666c22ce5",
      "metadata": {
        "id": "d71f245a-c474-4723-a1c8-ea4666c22ce5"
      },
      "source": [
        "The code used for Question 2 should make this very easy. For example, the following is the start of a complete solution using T5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75cf2f9-bedc-48e6-a367-747008002eed",
      "metadata": {
        "id": "d75cf2f9-bedc-48e6-a367-747008002eed"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "class T5RecogsModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encdec = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "    def forward(self, X_pad, X_mask, y_pad, y_mask, labels=None):\n",
        "        outputs = self.encdec(\n",
        "            input_ids=X_pad,\n",
        "            attention_mask=X_mask,\n",
        "            decoder_attention_mask=y_mask,\n",
        "            labels=y_pad)\n",
        "        return outputs\n",
        "\n",
        "class T5RecogsModel(RecogsModel):\n",
        "    def __init__(self, *args, initialize=True, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.enc_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "        self.dec_tokenizer = self.enc_tokenizer\n",
        "\n",
        "    def build_graph(self):\n",
        "        return T5RecogsModule()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613ca475-f788-441a-a32e-f3feed6aa88b",
      "metadata": {
        "id": "613ca475-f788-441a-a32e-f3feed6aa88b"
      },
      "source": [
        "This will make predictions, but they will be pretty totally disconnected from our task right now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eded1da8-e9ba-4cf8-a5ef-6d6c7c41ccf2",
      "metadata": {
        "id": "eded1da8-e9ba-4cf8-a5ef-6d6c7c41ccf2"
      },
      "outputs": [],
      "source": [
        "t5mod = T5RecogsModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9074288-99ea-41d8-8430-7a6887957953",
      "metadata": {
        "id": "b9074288-99ea-41d8-8430-7a6887957953"
      },
      "outputs": [],
      "source": [
        "t5_exs = dataset['dev'].input[: 2]\n",
        "\n",
        "t5_exs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a683db7-38de-49b0-b2d2-92cebeb1daa0",
      "metadata": {
        "id": "0a683db7-38de-49b0-b2d2-92cebeb1daa0"
      },
      "outputs": [],
      "source": [
        "t5mod.predict(t5_exs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e21f911-69d3-4fa1-b3eb-6c73b494a15c",
      "metadata": {
        "id": "3e21f911-69d3-4fa1-b3eb-6c73b494a15c"
      },
      "source": [
        "This model needs to be fine-tuned on ReCOGS, which you can do with its `fit` method. In that case, you will want to pay a lot of attention to the optimization-related parameters to `TorchModelBase`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c15c129-8ada-4114-9c59-42ebc8025b59",
      "metadata": {
        "id": "2c15c129-8ada-4114-9c59-42ebc8025b59"
      },
      "source": [
        "### Option: Training a seq2seq model from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "168e69f3-a5dd-4288-8d6c-ae652dac6365",
      "metadata": {
        "id": "168e69f3-a5dd-4288-8d6c-ae652dac6365"
      },
      "source": [
        "The above code for T5 is easily adapted to use a randomly initialized model. The config files used to train our core model are `encoder_config.json` and `decoder_config.json` in `SRC_DIRNAME`. These might be a good starting point in terms of parameters and other set-up details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f6ee76-5119-4e89-ac12-42d2933bb2b0",
      "metadata": {
        "id": "a5f6ee76-5119-4e89-ac12-42d2933bb2b0"
      },
      "source": [
        "### There are lots more options!\n",
        "\n",
        "Maybe a symbolic solver? A learned semantic parser? Tree-structured neural network?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "521ebabe-bfa7-4559-b7a6-e677b9241815",
      "metadata": {
        "id": "521ebabe-bfa7-4559-b7a6-e677b9241815"
      },
      "source": [
        "## Question 5: Bakeoff entry [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab31552-ed3c-41cc-b187-d45ec408a3ba",
      "metadata": {
        "id": "cab31552-ed3c-41cc-b187-d45ec408a3ba"
      },
      "source": [
        "Here we read in the bakeoff dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f943f3-de8c-4f0c-924e-8c705be013b3",
      "metadata": {
        "id": "c8f943f3-de8c-4f0c-924e-8c705be013b3"
      },
      "outputs": [],
      "source": [
        "bakeoff_df = pd.read_csv(\n",
        "    os.path.join(SRC_DIRNAME, \"cs224u-recogs-test-unlabeled.tsv\"),\n",
        "    sep=\"\\t\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "588b8d2c-169e-4fd5-a4d6-004d70b0b0d2",
      "metadata": {
        "id": "588b8d2c-169e-4fd5-a4d6-004d70b0b0d2"
      },
      "source": [
        "For the bakeoff entry, you should add a column \"prediction\" containing your predicted LFs and then use the following command to write the file to disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb3120b-a736-464a-a387-9a3bdc9bdcfc",
      "metadata": {
        "id": "9eb3120b-a736-464a-a387-9a3bdc9bdcfc"
      },
      "outputs": [],
      "source": [
        "bakeoff_df.to_csv(\"cs224u-recogs-bakeoff-entry.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "943bac05-b45d-4f0b-9ad8-e52b83b9760f",
      "metadata": {
        "id": "943bac05-b45d-4f0b-9ad8-e52b83b9760f"
      },
      "source": [
        "Here is what the first couple of lines of the file should look like:\n",
        "\n",
        "```\n",
        "\tinput\tcategory\tprediction\n",
        "0\tA cake was blessed by the wolf .\tactive_to_passive\tPREDICTED LF\n",
        "1\tA melon was blessed by a boy .\tactive_to_passive\tPREDICTED LF\n",
        "```\n",
        "\n",
        "where `PREDICTED LF` is what you predicted. Here is a quick test you can run locally to ensure that the autograder won't fail:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5eec46-2508-4818-a9ff-1989f99bfdfb",
      "metadata": {
        "id": "cd5eec46-2508-4818-a9ff-1989f99bfdfb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "def test_bakeoff_file(filename=\"cs224u-recogs-bakeoff-entry.tsv\"):\n",
        "    ref_filename = os.path.join(SRC_DIRNAME, \"cs224u-recogs-test-unlabeled.tsv\")\n",
        "    ref_df = pd.read_csv(ref_filename, sep=\"\\t\", index_col=0)\n",
        "\n",
        "    entry_df = pd.read_csv(filename, sep=\"\\t\", index_col=0)\n",
        "\n",
        "    errcount = 0\n",
        "\n",
        "    # Check expected columns:\n",
        "    expected_cols = [\"input\", \"category\", \"prediction\"]\n",
        "    for col in expected_cols:\n",
        "        if col not in entry_df.columns:\n",
        "            errcount += 1\n",
        "            print(f\"Missing column: {col}\")\n",
        "    if errcount > 0:\n",
        "        return\n",
        "\n",
        "    # Use the \"category\" column as a check that the rows have not\n",
        "    # been shuffled:\n",
        "    if not entry_df.category.equals(ref_df.category):\n",
        "        errcount += 1\n",
        "        print(\"Rows do not seem to be aligned with reference file. \"\n",
        "              \"Might they have gotten shuffled?\")\n",
        "\n",
        "    # Check that the predictions all have type str:\n",
        "    for line_num, x in enumerate(entry_df.prediction, start=1):\n",
        "        if not isinstance(x, str):\n",
        "            errcount += 1\n",
        "            print(f\"Prediction on line {line_num} is not a str: {x}\")\n",
        "\n",
        "    if errcount == 0:\n",
        "        print(\"Bakeoff file seems to be in good shape!\")\n",
        "        files.download(ref_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d37fe9-6014-4fac-b9d6-5552a01ce72c",
      "metadata": {
        "id": "26d37fe9-6014-4fac-b9d6-5552a01ce72c"
      },
      "outputs": [],
      "source": [
        "test_bakeoff_file(\"cs224u-recogs-bakeoff-entry.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFlB7ypUiHH-",
      "metadata": {
        "id": "qFlB7ypUiHH-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "toc-showtags": false,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01b11c312e444a5c9836bfea8a9f2218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dcf8bfa320049ee95a8097615957fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111244632b7041e6933e2efb46719ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d812a67cb8145688ff02e0f68854458": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2196fc66a3ef493bb4a54fe631517fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67d9c1e6dd8f467f9c7522398e698890",
              "IPY_MODEL_c39f05e3a11348729da9a3e0ed0c08c0",
              "IPY_MODEL_72df332aa5cf434dbb25237c32d7d604"
            ],
            "layout": "IPY_MODEL_1d812a67cb8145688ff02e0f68854458"
          }
        },
        "3534a36288a942579b40c65cfa1ef6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36c51e2008154917855bc06d3875f4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111244632b7041e6933e2efb46719ca6",
            "max": 5047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68609997b84a4bf59396a4e1f7cb4579",
            "value": 5047
          }
        },
        "5de7087734374d5c9bc93cac4146c88a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d9c1e6dd8f467f9c7522398e698890": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de7087734374d5c9bc93cac4146c88a",
            "placeholder": "​",
            "style": "IPY_MODEL_3534a36288a942579b40c65cfa1ef6d5",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "68609997b84a4bf59396a4e1f7cb4579": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "689d2bc2aaa24527b419d8c974e746ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afa5992605f64c0497f5cb66e4132bf8",
              "IPY_MODEL_36c51e2008154917855bc06d3875f4b7",
              "IPY_MODEL_d65211c844374ed3a4ba41bd661dc215"
            ],
            "layout": "IPY_MODEL_dd52c09f16534b5e93dbf5d9fe5dfab2"
          }
        },
        "72df332aa5cf434dbb25237c32d7d604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad6918382a6442b85504803107a56a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f8a025cc1b234257ba06ced5da48e89b",
            "value": " 17.4M/17.4M [00:00&lt;00:00, 29.1MB/s]"
          }
        },
        "74678011ae4d4dbc83477c52f6c4ad62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad6918382a6442b85504803107a56a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa5992605f64c0497f5cb66e4132bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d869992817438db8d3653a36aea953",
            "placeholder": "​",
            "style": "IPY_MODEL_74678011ae4d4dbc83477c52f6c4ad62",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c39f05e3a11348729da9a3e0ed0c08c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec176db4feab4191bd2edb02ac8a4efa",
            "max": 17417321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01b11c312e444a5c9836bfea8a9f2218",
            "value": 17417321
          }
        },
        "c3d869992817438db8d3653a36aea953": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1093d9d1ec469c8712265bebab2eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d65211c844374ed3a4ba41bd661dc215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dcf8bfa320049ee95a8097615957fd6",
            "placeholder": "​",
            "style": "IPY_MODEL_cc1093d9d1ec469c8712265bebab2eff",
            "value": " 5.05k/5.05k [00:00&lt;00:00, 124kB/s]"
          }
        },
        "dd52c09f16534b5e93dbf5d9fe5dfab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec176db4feab4191bd2edb02ac8a4efa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a025cc1b234257ba06ced5da48e89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
